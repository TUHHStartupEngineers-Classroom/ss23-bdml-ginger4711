{
  "hash": "e6e50a02df73bed66cf675cfbb118add",
  "result": {
    "markdown": "---\ntitle: \"Deep Learning\"\nauthor: \"Christian SÃ¼hl\"\noutput:\n  html_document:\n    toc: TRUE\n    theme: united\n---\n\n# Business case\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-1_66f98472c995a716dfba66b090c78963'}\n\n```{.r .cell-code}\nlibrary(keras)\n\nfashion_mnist <- dataset_fashion_mnist()\n\nc(train_images, train_labels) %<-% fashion_mnist$train\nc(test_images, test_labels) %<-% fashion_mnist$test\n\nclass_names = c(\"T-shirt/top\",\n                \"Trouser\",\n                \"Pullover\",\n                \"Dress\",\n                \"Coat\", \n                \"Sandal\",\n                \"Shirt\",\n                \"Sneaker\",\n                \"Bag\",\n                \"Ankle boot\")\n```\n:::\n\n## Explore the data\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-2_9c9cf96af4e9d678e8402577765c8eff'}\n\n```{.r .cell-code}\ndim(train_images)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60000    28    28\n```\n:::\n\n```{.r .cell-code}\n## [1] 60000    28    28\ndim(test_images)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10000    28    28\n```\n:::\n\n```{.r .cell-code}\n## [1] 10000    28    28\ndim(train_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 60000\n```\n:::\n\n```{.r .cell-code}\n## [1] 60000\ndim(test_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10000\n```\n:::\n\n```{.r .cell-code}\n## [1] 10000\n\ntrain_labels %>% \n          unique() %>% \n          sort()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0 1 2 3 4 5 6 7 8 9\n```\n:::\n\n```{.r .cell-code}\n## [1] 0 1 2 3 4 5 6 7 8 9\n\ntrain_labels[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9\n```\n:::\n\n```{.r .cell-code}\n## [1] 9\n\nclass_names[9 + 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Ankle boot\"\n```\n:::\n\n```{.r .cell-code}\n## [1] \"Ankle boot\"\n```\n:::\n\n## Preprocess the data \n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-3_6f41870379c65c90513bb83071c31865'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.1     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rlang)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'rlang'\n\nThe following objects are masked from 'package:purrr':\n\n    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n    flatten_raw, invoke, splice\n```\n:::\n\n```{.r .cell-code}\nimage_1 <- train_images[1, , ] %>% \n\n                # Convert matrix to a tibble (with unique col names)\n                as_tibble(.name_repair = \"unique\") %>% \n                \n                # Set the names according to the col number\n                set_names( seq_len(ncol(.)) ) %>% \n                \n                # Create a column for the rownumbers\n                mutate(y = seq_len(nrow(.))) %>% \n                \n                # Make the data long, so that we have x/y value pairs\n                pivot_longer(cols = c(1:28), names_to        = \"x\", \n                                             values_to       = \"value\", \n                                             names_transform = list(x = as.integer))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n* `` -> `...3`\n* `` -> `...4`\n* `` -> `...5`\n* `` -> `...6`\n* `` -> `...7`\n* `` -> `...8`\n* `` -> `...9`\n* `` -> `...10`\n* `` -> `...11`\n* `` -> `...12`\n* `` -> `...13`\n* `` -> `...14`\n* `` -> `...15`\n* `` -> `...16`\n* `` -> `...17`\n* `` -> `...18`\n* `` -> `...19`\n* `` -> `...20`\n* `` -> `...21`\n* `` -> `...22`\n* `` -> `...23`\n* `` -> `...24`\n* `` -> `...25`\n* `` -> `...26`\n* `` -> `...27`\n* `` -> `...28`\n```\n:::\n\n```{.r .cell-code}\nimage_1 %>% ggplot(aes(x = x, y = y, fill = value)) +\n\n            # Add tiles and fill them with a white/black gradient\n            geom_tile() +\n            scale_fill_gradient(low = \"white\", high = \"black\", na.value = NA) +\n            \n            # Turn image upside down\n            scale_y_reverse() +\n            \n            # Formatting\n            theme_minimal() +\n            theme(panel.grid = element_blank()) +\n            xlab(\"\") +\n            ylab(\"\")\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntrain_images <- train_images / 255\ntest_images  <- test_images / 255\n\nplot_image <- function(idx) {\n  \n  image_idx <- train_images[idx, , ] %>% \n                as_tibble(.name_repair = \"unique\") %>% \n                set_names(seq_len(ncol(.))) %>% \n                mutate(y = seq_len(nrow(.))) %>% \n                pivot_longer(cols = c(1:28), names_to        = \"x\", \n                                             values_to       = \"value\", \n                                             names_transform = list(x = as.integer))\n\n    g     <- image_idx %>% \n              ggplot(aes(x = x, y = y, fill = value)) +\n              geom_tile() +\n              scale_fill_gradient(low = \"white\", high = \"black\", na.value = NA) +\n              scale_y_reverse() +\n              theme_minimal() +\n              theme(panel.grid = element_blank(),\n                    legend.position = \"none\",\n                    axis.text = element_blank()) + \n                    \n              # Add the label (add 1, because it is 0-indexed)      \n              xlab(class_names[train_labels[idx] + 1]) +\n              ylab(\"\")\n\n      return(g)\n\n}\n\nlibrary(cowplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n```\n:::\n\n```{.r .cell-code}\nimage_lst <- map(c(1:25), plot_image)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n* `` -> `...3`\n* `` -> `...4`\n* `` -> `...5`\n* `` -> `...6`\n* `` -> `...7`\n* `` -> `...8`\n* `` -> `...9`\n* `` -> `...10`\n* `` -> `...11`\n* `` -> `...12`\n* `` -> `...13`\n* `` -> `...14`\n* `` -> `...15`\n* `` -> `...16`\n* `` -> `...17`\n* `` -> `...18`\n* `` -> `...19`\n* `` -> `...20`\n* `` -> `...21`\n* `` -> `...22`\n* `` -> `...23`\n* `` -> `...24`\n* `` -> `...25`\n* `` -> `...26`\n* `` -> `...27`\n* `` -> `...28`\n```\n:::\n\n```{.r .cell-code}\nplot_grid(plotlist = image_lst)\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n## Build the model\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-4_3db568715a3369b6ebe7e6198f6fd389'}\n\n```{.r .cell-code}\n# Setup the layers\nmodel <- keras_model_sequential()\nmodel %>%\n  layer_flatten(input_shape = c(28, 28)) %>%\n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dense(units = 10, activation = 'softmax')\n\n# Compile the model\nmodel %>% compile(\n  optimizer = 'adam', \n  loss = 'sparse_categorical_crossentropy',\n  metrics = c('accuracy')\n)\n \n# Train the mdoel\nmodel %>% fit(train_images, train_labels, epochs = 5, verbose = 2)\n\n# Evaluate accuracy\nscore <- model %>% evaluate(test_images, test_labels, verbose = 0)\nscore\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     loss  accuracy \n0.3614648 0.8725000 \n```\n:::\n\n```{.r .cell-code}\n# Make Predictions\npredictions <- model %>% predict(test_images)\npredictions[1, ] %>% which.max()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\n## Plot predictions\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-5_8899d3d781ba4b4a91e1a065bdb643ee'}\n\n```{.r .cell-code}\n## 1. Create function\nplot_predictions <- function(idx) {\n  \n  # Get image in the correct format\n  image_test <- test_images[idx, , ] %>% \n                    as_tibble(.name_repair = \"unique\") %>% \n                    set_names( seq_len(ncol(.)) ) %>% \n                    mutate(y = seq_len(nrow(.))) %>% \n                    pivot_longer(cols = c(1:28), \n                                 names_to        = \"x\", \n                                 values_to       = \"value\", \n                                 names_transform = list(x = as.integer))\n\n  # Get true and predicted labels\n  # subtract 1 as labels go from 0 to 9\n  predicted_label <- which.max(predictions[idx, ]) - 1\n  true_label      <- test_labels[idx]\n  color           <- ifelse(predicted_label == true_label, \"#008800\", \"#bb0000\")\n  \n  # Plot\n  g <- image_test %>% \n          ggplot(aes(x = x, y = y, fill = value)) +\n          geom_tile() +\n          scale_fill_gradient(low = \"white\", high = \"black\", na.value = NA) +\n          scale_y_reverse() +\n          theme_minimal() +\n          theme(panel.grid = element_blank(),\n                legend.position = \"none\",\n                axis.text = element_blank(),\n                axis.title.x = element_text(color = color, face = \"bold\")) + \n          xlab(paste0(\n            class_names[predicted_label + 1], \n            \" (\",\n            class_names[true_label + 1], \")\")) +\n          ylab(\"\")\n  \n    return(g)\n\n}\n\n## 2. map over indices\npredictions_lst <- map(c(1:25), plot_predictions)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n* `` -> `...3`\n* `` -> `...4`\n* `` -> `...5`\n* `` -> `...6`\n* `` -> `...7`\n* `` -> `...8`\n* `` -> `...9`\n* `` -> `...10`\n* `` -> `...11`\n* `` -> `...12`\n* `` -> `...13`\n* `` -> `...14`\n* `` -> `...15`\n* `` -> `...16`\n* `` -> `...17`\n* `` -> `...18`\n* `` -> `...19`\n* `` -> `...20`\n* `` -> `...21`\n* `` -> `...22`\n* `` -> `...23`\n* `` -> `...24`\n* `` -> `...25`\n* `` -> `...26`\n* `` -> `...27`\n* `` -> `...28`\n```\n:::\n\n```{.r .cell-code}\n## 3. Plot list\nplot_grid(plotlist = predictions_lst)\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Completly new images\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-6_6a12996ce58f19b84f1ff810ec7e5444'}\n\n```{.r .cell-code}\nlibrary(imager)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: magrittr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'magrittr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:rlang':\n\n    set_names\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    set_names\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'imager'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:magrittr':\n\n    add\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:cowplot':\n\n    draw_text\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stringr':\n\n    boundary\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    where\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:tidyr':\n\n    fill\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    convolve, spectrum\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:graphics':\n\n    frame\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:base':\n\n    save.image\n```\n:::\n\n```{.r .cell-code}\nimg_new <- load.image(\"t-shirt.jpg\") %>% \n                resize(size_x = 28, size_y = 28, size_z = 1, size_c = 1) %>% \n                imrotate(angle = -90) %>% \n                as.array() %>% \n                drop() %>% \n                array(dim = c(1,28,28)) %>% \n                subtract(1) %>% \n                abs() \n\npar(mfrow=c(1,2)) # set the plotting area into a 1*2 array   \nplot(as.cimg(img_new[1,,]),     main = \"img_new\",  axes=FALSE)\nplot(as.cimg(test_images[1,,]), main = \"img_test\", axes=FALSE)\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\npredictions <- model %>% predict(img_new[1, , , drop = FALSE])\nprediction  <- predictions[1, ] - 1\nwhich.max(prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\n## [1] 1\n\nclass_pred <- model %>% predict(img_new) %>% which.max() - 1\nclass_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n## [1] 0\nclass_names[class_pred + 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"T-shirt/top\"\n```\n:::\n\n```{.r .cell-code}\n## [1] \"T-shirt/top\"\n```\n:::\n\n# Challenge\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-7_6202a7e97f901da21efe9a75ac450f3b'}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(tidyverse)\nlibrary(keras)\nlibrary(lime)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lime'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    explain\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'recipes'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stringr':\n\n    fixed\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nlibrary(yardstick)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFor binary classification, the first factor level is assumed to be the event.\nUse the argument `event_level = \"second\"` to alter this as needed.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'yardstick'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:readr':\n\n    spec\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:keras':\n\n    get_weights\n```\n:::\n\n```{.r .cell-code}\nlibrary(corrr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'corrr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:imager':\n\n    correlate\n```\n:::\n\n```{.r .cell-code}\nchurn_data_raw <- read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 7043 Columns: 21\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (17): customerID, gender, Partner, Dependents, PhoneService, MultipleLin...\ndbl  (4): SeniorCitizen, tenure, MonthlyCharges, TotalCharges\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nglimpse(churn_data_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 7,043\nColumns: 21\n$ customerID       <chr> \"7590-VHVEG\", \"5575-GNVDE\", \"3668-QPYBK\", \"7795-CFOCW~\n$ gender           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\",~\n$ SeniorCitizen    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n$ Partner          <chr> \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes~\n$ Dependents       <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\"~\n$ tenure           <dbl> 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2~\n$ PhoneService     <chr> \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", ~\n$ MultipleLines    <chr> \"No phone service\", \"No\", \"No\", \"No phone service\", \"~\n$ InternetService  <chr> \"DSL\", \"DSL\", \"DSL\", \"DSL\", \"Fiber optic\", \"Fiber opt~\n$ OnlineSecurity   <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"~\n$ OnlineBackup     <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"N~\n$ DeviceProtection <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Y~\n$ TechSupport      <chr> \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes~\n$ StreamingTV      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye~\n$ StreamingMovies  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes~\n$ Contract         <chr> \"Month-to-month\", \"One year\", \"Month-to-month\", \"One ~\n$ PaperlessBilling <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", ~\n$ PaymentMethod    <chr> \"Electronic check\", \"Mailed check\", \"Mailed check\", \"~\n$ MonthlyCharges   <dbl> 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7~\n$ TotalCharges     <dbl> 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949~\n$ Churn            <chr> \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Y~\n```\n:::\n:::\n\n## Preprocess data\n| Since there is no column named \"Target\" i left that statement commented out.\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-8_19ac52bad822fd9b287e2253d78bd624'}\n\n```{.r .cell-code}\n# Prune the data\nchurn_data_tbl <- churn_data_raw %>%\n                  select(-customerID) %>% # Remove customerId column\n                  drop_na(TotalCharges) %>% # Drop Not a number from Total Charges\n                  select(Churn,everything())\n\n# Split test/training sets\nset.seed(100)\nsplit_obj <- rsample::initial_split(churn_data_tbl, prop   = 0.80)\ntrain_tbl <- training(split_obj)\ntest_tbl  <- testing(split_obj)\n\nchurn_data_tbl %>% ggplot(aes(x = tenure)) + \n                     geom_histogram(binwidth = 0.5, fill =  \"#2DC6D6\") +\n                     labs(\n                       title = \"Tenure Counts Without Binning\",\n                       x     = \"tenure (month)\"\n                       )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nchurn_data_tbl %>% ggplot(aes(x = tenure)) + \n  geom_histogram(bins = 6, color = \"white\", fill =  \"#2DC6D6\") +\n  labs(\n    title = \"Tenure Counts With Six Bins\",\n    x     = \"tenure (month)\"\n  )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n## Log transformation\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-9_56f991c49e673e5d9c1c13cf62a2c3a4'}\n\n```{.r .cell-code}\n# Determine if log transformation improves correlation \n# between TotalCharges and Churn\n\ntrain_tbl %>%\n    select(Churn, TotalCharges) %>%\n    mutate(\n        Churn = Churn %>% as.factor() %>% as.numeric(),\n        LogTotalCharges = log(TotalCharges)\n        ) %>%\n    correlate() %>%\n    focus(Churn) %>%\n    fashion()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCorrelation computed with\n* Method: 'pearson'\n* Missing treated using: 'pairwise.complete.obs'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n             term Churn\n1    TotalCharges  -.21\n2 LogTotalCharges  -.25\n```\n:::\n\n```{.r .cell-code}\nchurn_data_tbl %>% \n        pivot_longer(cols      = c(Contract, InternetService, MultipleLines, PaymentMethod), \n                     names_to  = \"feature\", \n                     values_to = \"category\") %>% \n        ggplot(aes(category)) +\n          geom_bar(fill = \"#2DC6D6\") +\n          facet_wrap(~ feature, scales = \"free\") +\n          labs(\n            title = \"Features with multiple categories: Need to be one-hot encoded\"\n          ) +\n          theme(axis.text.x = element_text(angle = 25, \n                                           hjust = 1))\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## \n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-10_fa6760583ac4bced705c2e73159632b0'}\n\n```{.r .cell-code}\nrec_obj <- recipe(Churn ~ ., data = train_tbl) %>%\n    step_rm(Churn) %>% \n    step_discretize(tenure, options = list(cuts = 6)) %>%\n    step_log(TotalCharges) %>%\n    step_dummy(all_nominal(), -all_outcomes(), one_hot = T) %>%\n    step_center(all_predictors(), -all_outcomes()) %>%\n    step_scale(all_predictors(), -all_outcomes()) %>%\n    prep(data = train_tbl)\n\n# Predictors\nx_train_tbl <- bake( rec_obj , train_tbl )\nx_test_tbl  <- bake( rec_obj , test_tbl )\n\n# Response variables for training and testing sets\ny_train_vec <- ifelse( train_tbl$Churn == \"Yes\",1,0 )\ny_test_vec  <- ifelse( test_tbl$Churn == \"Yes\",1,0 )\n```\n:::\n\n## Build keras model\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-11_d02c8fc0be7570ac87576205dce11e1f'}\n\n```{.r .cell-code}\n# Building our Artificial Neural Network\nmodel_keras <- keras_model_sequential()\n\nmodel_keras %>% \n    # First hidden layer\n    layer_dense(\n        units              = 16, \n        kernel_initializer = \"uniform\", \n        activation         = \"relu\", \n        input_shape        = ncol(x_train_tbl)) %>% \n    # Dropout to prevent overfitting\n    layer_dropout(rate = 0.1) %>%\n    # Second hidden layer\n    layer_dense(\n        units              = 16, \n        kernel_initializer = \"uniform\", \n        activation         = \"relu\") %>% \n    # Dropout to prevent overfitting\n    layer_dropout(rate = 0.1) %>%\n    # Output layer\n    layer_dense(\n        units              = 1, \n        kernel_initializer = \"uniform\", \n        activation         = \"sigmoid\") %>% \n    # Compile ANN\n    compile(\n        optimizer = 'adam',\n        loss      = 'binary_crossentropy',\n        metrics   = c('accuracy')\n    )\nmodel_keras\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_2 (Dense)                    (None, 16)                      816         \n dropout_1 (Dropout)                (None, 16)                      0           \n dense_1 (Dense)                    (None, 16)                      272         \n dropout (Dropout)                  (None, 16)                      0           \n dense (Dense)                      (None, 1)                       17          \n================================================================================\nTotal params: 1,105\nTrainable params: 1,105\nNon-trainable params: 0\n________________________________________________________________________________\n```\n:::\n\n```{.r .cell-code}\nx_train_mtx = as.matrix(x_train_tbl)\ny_train_mtx = as.matrix(y_train_vec)\nx_test_mtx = as.matrix(x_test_tbl)\ny_test_mtx = as.matrix(y_test_vec)\n\n# Fit the keras model to the training data\nfit_keras <- fit(\n    model_keras,\n    batch_size       = 50 , \n    epochs           = 35 , \n    validation_split = 0.3,\n    x = x_train_mtx,\n    y = y_train_mtx,\n    validation_data = list(x_test_mtx,y_test_mtx)\n    )\n\nfit_keras\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFinal epoch (plot to see history):\n        loss: 0.3941\n    accuracy: 0.819\n    val_loss: 0.4285\nval_accuracy: 0.7903 \n```\n:::\n:::\n\n## Predictions\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-12_ecaec3a1f6b62e538839f53ec3d80cb2'}\n\n```{.r .cell-code}\n# Predicted Class\nyhat_keras_class_vec <- predict(object = model_keras, x = as.matrix(x_test_tbl)) %>%\n    as.vector() %>%\n    round()\n\n# Predicted Class Probability\nyhat_keras_prob_vec  <- predict(object = model_keras, x = as.matrix(x_test_tbl)) %>%\n    as.vector() %>%\n    round()\n\n# Format test data and predictions for yardstick metrics\nestimates_keras_tbl <- tibble(\n    truth      = as.factor(y_test_vec) %>% fct_recode(yes = \"1\", no = \"0\"),\n    estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = \"1\", no = \"0\"),\n    class_prob = yhat_keras_prob_vec\n)\n\nestimates_keras_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,407 x 3\n   truth estimate class_prob\n   <fct> <fct>         <dbl>\n 1 yes   no                0\n 2 no    no                0\n 3 no    no                0\n 4 no    no                0\n 5 no    no                0\n 6 no    no                0\n 7 no    no                0\n 8 no    no                0\n 9 no    no                0\n10 yes   yes               1\n# i 1,397 more rows\n```\n:::\n\n```{.r .cell-code}\n# Confusion matrix\nconfusion_matrix <- estimates_keras_tbl %>% conf_mat(truth,estimate)\nconfusion_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction  no yes\n       no  926 174\n       yes 121 186\n```\n:::\n\n```{.r .cell-code}\n# Accuracy\nacc <- estimates_keras_tbl %>% accuracy(truth,estimate)\nacc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.790\n```\n:::\n\n```{.r .cell-code}\n# AUC\nauc <- estimates_keras_tbl %>% roc_auc(truth,class_prob,event_level=\"second\")\nauc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.701\n```\n:::\n\n```{.r .cell-code}\n# Precision\ntibble(\n    precision = estimates_keras_tbl %>% precision(truth,estimate),\n    recall    = estimates_keras_tbl %>% recall(truth,estimate)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 2\n  precision$.metric $.estimator $.estimate recall$.metric $.estimator $.estimate\n  <chr>             <chr>            <dbl> <chr>          <chr>            <dbl>\n1 precision         binary           0.842 recall         binary           0.884\n```\n:::\n\n```{.r .cell-code}\n# F1-Statistic\nestimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 f_meas  binary         0.863\n```\n:::\n:::\n\n## Lime\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-13_c483031aa2330bf88b8ffddae0d81b5f'}\n\n```{.r .cell-code}\nclass(model_keras)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"keras.engine.sequential.Sequential\"                     \n [2] \"keras.engine.functional.Functional\"                     \n [3] \"keras.engine.training.Model\"                            \n [4] \"keras.engine.base_layer.Layer\"                          \n [5] \"tensorflow.python.module.module.Module\"                 \n [6] \"tensorflow.python.trackable.autotrackable.AutoTrackable\"\n [7] \"tensorflow.python.trackable.base.Trackable\"             \n [8] \"keras.utils.version_utils.LayerVersionSelector\"         \n [9] \"keras.utils.version_utils.ModelVersionSelector\"         \n[10] \"python.builtin.object\"                                  \n```\n:::\n\n```{.r .cell-code}\n# Setup lime::model_type() function for keras\nmodel_type.keras.engine.sequential.Sequential  <- function(x, ...) {\n    return(\"classification\")\n}\n\n# Setup lime::predict_model() function for keras\npredict_model.keras.engine.sequential.Sequential <- function(x, newdata, type, ...) {\n    pred <- predict(object = x, x = as.matrix(newdata))\n    return(data.frame(Yes = pred, No = 1 - pred))\n}\n\nlibrary(lime)\n# Test our predict_model() function\npredict_model(x = model_keras, newdata = x_test_tbl, type = 'raw') %>%\n    tibble::as_tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,407 x 2\n      Yes    No\n    <dbl> <dbl>\n 1 0.275  0.725\n 2 0.142  0.858\n 3 0.142  0.858\n 4 0.287  0.713\n 5 0.0206 0.979\n 6 0.0268 0.973\n 7 0.0123 0.988\n 8 0.325  0.675\n 9 0.403  0.597\n10 0.771  0.229\n# i 1,397 more rows\n```\n:::\n\n```{.r .cell-code}\n# Run lime() on training set\nexplainer <- lime::lime(\n    x            = x_train_tbl, \n    model            = model_keras,\n    bin_continuous = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: SeniorCitizen does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: gender_Female does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: gender_Male does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Partner_No does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Partner_Yes does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Dependents_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Dependents_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin1 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin2 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin3 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin4 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin5 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: tenure_bin6 does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PhoneService_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PhoneService_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: MultipleLines_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: MultipleLines_No.phone.service does not contain enough variance to use\nquantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: MultipleLines_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: InternetService_DSL does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: InternetService_Fiber.optic does not contain enough variance to use\nquantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: InternetService_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineSecurity_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineSecurity_No.internet.service does not contain enough variance to\nuse quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineSecurity_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineBackup_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineBackup_No.internet.service does not contain enough variance to\nuse quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: OnlineBackup_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: DeviceProtection_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: DeviceProtection_No.internet.service does not contain enough variance\nto use quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: DeviceProtection_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: TechSupport_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: TechSupport_No.internet.service does not contain enough variance to\nuse quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: TechSupport_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingTV_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingTV_No.internet.service does not contain enough variance to\nuse quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingTV_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingMovies_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingMovies_No.internet.service does not contain enough variance\nto use quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: StreamingMovies_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Contract_Month.to.month does not contain enough variance to use\nquantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Contract_One.year does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Contract_Two.year does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaperlessBilling_No does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaperlessBilling_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaymentMethod_Bank.transfer..automatic. does not contain enough\nvariance to use quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaymentMethod_Credit.card..automatic. does not contain enough variance\nto use quantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaymentMethod_Electronic.check does not contain enough variance to use\nquantile binning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: PaymentMethod_Mailed.check does not contain enough variance to use\nquantile binning. Using standard binning instead.\n```\n:::\n\n```{.r .cell-code}\nexplanation <- lime::explain(\n    x = x_test_tbl[1:10,], \n    explainer    = explainer, \n    n_labels     = 2, \n    n_features   = 50)\n```\n:::\n\n## Plot\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-14_7d21a10a029309c6af7822021921ea9f'}\n\n```{.r .cell-code}\nplot_features(explanation)\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_explanations(explanation)\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n## Correlation analysis\n### Feature correlations to Churn\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-15_2ea9657c829e45812ae7de3b013979d7'}\n\n```{.r .cell-code}\ncorrr_analysis <- x_train_tbl %>%\n    mutate(Churn = y_train_vec) %>%\n    correlate() %>%\n    focus(Churn) %>%\n    rename(feature = term) %>% # Changed rowname to term\n    arrange(abs(Churn)) %>%\n    mutate(feature = as_factor(feature)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCorrelation computed with\n* Method: 'pearson'\n* Missing treated using: 'pairwise.complete.obs'\n```\n:::\n\n```{.r .cell-code}\ncorrr_analysis\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 x 2\n   feature                           Churn\n   <fct>                             <dbl>\n 1 tenure_bin3                    -0.00179\n 2 gender_Female                   0.00421\n 3 gender_Male                    -0.00421\n 4 PhoneService_No                -0.0111 \n 5 PhoneService_Yes                0.0111 \n 6 MultipleLines_No.phone.service -0.0111 \n 7 MultipleLines_No               -0.0353 \n 8 MultipleLines_Yes               0.0424 \n 9 StreamingMovies_Yes             0.0518 \n10 StreamingTV_Yes                 0.0590 \n# i 40 more rows\n```\n:::\n:::\n\n### Correlation visualization\n\n::: {.cell hash='06_deep_learning_cache/html/unnamed-chunk-16_8f67d2137be0f0ecda9aad9115ce983d'}\n\n```{.r .cell-code}\ncorrr_analysis %>%\n  ggplot(aes(x = Churn, y = fct_reorder(feature, desc(Churn)))) +\n  geom_point() +\n  \n  # Positive Correlations - Contribute to churn\n  geom_segment(aes(xend = 0, yend = feature), \n               color = \"red\", \n               data = corrr_analysis %>% filter(Churn > 0)) +\n  geom_point(color = \"red\", \n             data = corrr_analysis %>% filter(Churn > 0)) +\n  \n  # Negative Correlations - Prevent churn\n  geom_segment(aes(xend = 0, yend = feature), \n               color = \"#2DC6D6\", \n               data = corrr_analysis %>% filter(Churn < 0)) +\n  geom_point(color = \"#2DC6D6\", \n             data = corrr_analysis %>% filter(Churn < 0)) +\n  \n  # Vertical lines\n  geom_vline(xintercept = 0, color = \"#f1fa8c\", size = 1, linetype = 2) +\n  geom_vline(xintercept = 0.25, color = \"#f1fa8c\", size = 0.5, linetype = 2) +\n  geom_vline(xintercept = -0.25, color = \"#f1fa8c\", size = 0.5, linetype = 2) +\n  \n  # Aesthetics\n  labs(x = \"Churn\", y = \"Feature Importance\", title = \"Churn Correlation Analysis\\nPositive Correlations (contribute to churn), Negative Correlations (prevent Churn)\",)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\nBDML fertig stellen\nGucken, ob beide Webseiten online gehen\nGucken, ob das Password fÃ¼r beide funktioniert\nBeide Formulare neu ausfÃ¼llen",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}