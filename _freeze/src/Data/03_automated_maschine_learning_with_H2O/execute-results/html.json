{
  "hash": "195149c83dfd6d100df427791aa85edc",
  "result": {
    "markdown": "---\ntitle: \"Automated Maschine Learning with H2O\"\nauthor: \"Christian Sühl\"\noutput:\n  html_document:\n    toc: TRUE\n    theme: united\n---\n\n\n# Business case (Part I)\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-1_636aba6abe71246c91a744f8c9bf1786'}\n\n```{.r .cell-code}\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n----------------------------------------------------------------------\n\nYour next step is to start H2O:\n    > h2o.init()\n\nFor H2O package documentation, ask for help:\n    > ??h2o\n\nAfter starting H2O, you can use the Web UI at http://localhost:54321\nFor more information visit https://docs.h2o.ai\n\n----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n    log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\n# To launch H2O locally with default initialization arguments, use the following: \nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         1 hours 5 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.40.0.1 \n    H2O cluster version age:    3 months and 11 days \n    H2O cluster name:           H2O_started_from_R_Chris_yuh446 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.98 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.0.5 (2021-03-31) \n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-2_71e03229d038164d35aea2d6e20c1d1b'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.1     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx lubridate::day()   masks h2o::day()\nx dplyr::filter()    masks stats::filter()\nx lubridate::hour()  masks h2o::hour()\nx dplyr::lag()       masks stats::lag()\nx lubridate::month() masks h2o::month()\nx lubridate::week()  masks h2o::week()\nx lubridate::year()  masks h2o::year()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\ncar_stats <- function(groupby_var, measure_var) {\n    groupby_var <- enquo(groupby_var)\n    measure_var <- enquo(measure_var)\n    ret <- mtcars %>% \n             group_by(!!groupby_var) %>%\n             summarize(min = min(!!measure_var), max = max(!!measure_var)) %>%\n             # Optional: as_label() and \"walrus operator\" :=\n             mutate(measure_var = as_label(measure_var), !!measure_var := \"test\")\n    return(ret)\n}\ncar_stats(cyl,hp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 5\n    cyl   min   max measure_var hp   \n  <dbl> <dbl> <dbl> <chr>       <chr>\n1     4    52   113 hp          test \n2     6   105   175 hp          test \n3     8   150   335 hp          test \n```\n:::\n\n```{.r .cell-code}\nscatter_plot <- function(data, x_var, y_var) {\n  x_var <- enquo(x_var)\n  y_var <- enquo(y_var)\n  ret <- data %>% \n           ggplot(aes(x = !!x_var, y = !!y_var)) + \n           geom_point() + \n           geom_smooth() +\n           ggtitle(str_c(as_label(y_var), \" vs. \",as_label(x_var)))\n  return(ret)\n}\nscatter_plot(mtcars, cyl, hp)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 3.98\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 4.02\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 2.0055e-016\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 16.16\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at\n3.98\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : neighborhood radius\n4.02\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : reciprocal condition\nnumber 2.0055e-016\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predLoess(object$y, object$x, newx = if (is.null(newdata)) object$x\nelse if (is.data.frame(newdata))\nas.matrix(model.frame(delete.response(terms(object)), : There are other near\nsingularities as well. 16.16\n```\n:::\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-3_b365970b43a778bf0706ccc76f1403d2'}\n\n```{.r .cell-code}\nlibrary(readr)\n# Load data\nemployee_attrition_tbl <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1470 Columns: 35\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\ndbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# Business & Data Understanding: Department and Job Role\n\n# Data subset\ndept_job_role_tbl <- employee_attrition_tbl %>%\n  select(EmployeeNumber, Department, JobRole, PerformanceRating, Attrition)\n\ndept_job_role_tbl %>%\n\n  group_by(Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n  mutate(pct = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n  Attrition     n   pct\n  <chr>     <int> <dbl>\n1 No         1233 0.839\n2 Yes         237 0.161\n```\n:::\n\n```{.r .cell-code}\n# Attrition by department\ndept_job_role_tbl %>%\n\n  # Block 1\n  group_by(Department, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n\n  # Block 2: Caution: It's easy to inadvertently miss grouping when creating counts & percents within groups\n  group_by(Department) %>%\n  mutate(pct = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'Department'. You can override using the\n`.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 4\n# Groups:   Department [3]\n  Department             Attrition     n   pct\n  <chr>                  <chr>     <int> <dbl>\n1 Human Resources        No           51 0.810\n2 Human Resources        Yes          12 0.190\n3 Research & Development No          828 0.862\n4 Research & Development Yes         133 0.138\n5 Sales                  No          354 0.794\n6 Sales                  Yes          92 0.206\n```\n:::\n\n```{.r .cell-code}\n# Attrition by job role\ndept_job_role_tbl %>%\n\n  # Block 1\n  group_by(Department, JobRole, Attrition) %>%\n  summarize(n = n()) %>%\n  ungroup() %>%\n\n  # Block 2\n  group_by(Department, JobRole) %>%\n  mutate(pct = n / sum(n)) %>%\n  ungroup() %>%\n\n  # Block 3\n  filter(Attrition %in% \"Yes\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'Department', 'JobRole'. You can override\nusing the `.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 5\n   Department             JobRole                   Attrition     n    pct\n   <chr>                  <chr>                     <chr>     <int>  <dbl>\n 1 Human Resources        Human Resources           Yes          12 0.231 \n 2 Research & Development Healthcare Representative Yes           9 0.0687\n 3 Research & Development Laboratory Technician     Yes          62 0.239 \n 4 Research & Development Manager                   Yes           3 0.0556\n 5 Research & Development Manufacturing Director    Yes          10 0.0690\n 6 Research & Development Research Director         Yes           2 0.025 \n 7 Research & Development Research Scientist        Yes          47 0.161 \n 8 Sales                  Manager                   Yes           2 0.0541\n 9 Sales                  Sales Executive           Yes          57 0.175 \n10 Sales                  Sales Representative      Yes          33 0.398 \n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-4_10b37be5fb78a6d37fe7e1167e9f4791'}\n\n```{.r .cell-code}\n# Use this\n# Function to convert counts to percentages. \ncount_to_pct <- function(data, ..., col = n) {\n  # capture the dots\n  grouping_vars_expr <- quos(...)\n  col_expr <- enquo(col)\n  ret <- data %>%\n    group_by(!!! grouping_vars_expr) %>%\n    mutate(pct = (!! col_expr) / sum(!! col_expr)) %>%\n    ungroup()\n  return(ret)\n}\n\nassess_attrition <- function(data, attrition_col, attrition_value, baseline_pct) {\n\n  attrition_col_expr <- enquo(attrition_col)\n\n  data %>%\n  \n    # Use parenthesis () to give tidy eval evaluation priority\n    filter((!! attrition_col_expr) %in% attrition_value) %>%\n    arrange(desc(pct)) %>%\n    mutate(\n      # Function inputs in numeric format (e.g. baseline_pct = 0.088 don't require tidy eval)\n      above_industry_avg = case_when(\n        pct > baseline_pct ~ \"Yes\",\n        TRUE ~ \"No\"\n      )\n    )\n\n}\n\n# Function to calculate attrition cost\ncalculate_attrition_cost <- function(\n\n  # Employee\n  n                    = 1,\n  salary               = 80000,\n\n  # Direct Costs\n  separation_cost      = 500,\n  vacancy_cost         = 10000,\n  acquisition_cost     = 4900,\n  placement_cost       = 3500,\n\n  # Productivity Costs\n  net_revenue_per_employee = 250000,\n  workdays_per_year        = 240,\n  workdays_position_open   = 40,\n  workdays_onboarding      = 60,\n  onboarding_efficiency    = 0.50\n\n) {\n\n  # Direct Costs\n  direct_cost <- sum(separation_cost, vacancy_cost, acquisition_cost, placement_cost)\n\n  # Lost Productivity Costs\n  productivity_cost <- net_revenue_per_employee / workdays_per_year *\n    (workdays_position_open + workdays_onboarding * onboarding_efficiency)\n\n  # Savings of Salary & Benefits (Cost Reduction)\n  salary_benefit_reduction <- salary / workdays_per_year * workdays_position_open\n\n  # Estimated Turnover Per Employee\n  cost_per_employee <- direct_cost + productivity_cost - salary_benefit_reduction\n\n  # Total Cost of Employee Turnover\n  total_cost <- n * cost_per_employee\n\n  return(total_cost)\n\n}\n\n# Function to plot attrition\nplot_attrition <- function(data, \n                           ..., \n                           .value,\n                           fct_reorder = TRUE,\n                           fct_rev     = FALSE,\n                           include_lbl = TRUE,\n                           color       = \"#2dc6d6\",\n                           units       = c(\"0\", \"K\", \"M\")) {\n\n  ### Inputs\n  group_vars_expr   <- quos(...)\n  \n  # If the user does not supply anything, \n  # this takes the first column of the supplied data\n  if (length(group_vars_expr) == 0) {\n    group_vars_expr <- quos(rlang::sym(colnames(data)[[1]]))\n    }\n\n  value_expr <- enquo(.value)\n\n  units_val  <- switch(units[[1]],\n                       \"M\" = 1e6,\n                       \"K\" = 1e3,\n                       \"0\" = 1)\n  if (units[[1]] == \"0\") units <- \"\"\n\n  # Data Manipulation\n  # This is a so called Function Factory (a function that produces a function)\n  usd <- scales::dollar_format(prefix = \"$\", largest_with_cents = 1e3)\n\n  # Create the axis labels and values for the plot\n  data_manipulated <- data %>%\n    mutate(name = str_c(!!! group_vars_expr, sep = \": \") %>% as_factor()) %>%\n    mutate(value_text = str_c(usd(!! value_expr / units_val),\n                              units[[1]], sep = \"\"))\n\n  \n  # Order the labels on the y-axis according to the input\n  if (fct_reorder) {\n    data_manipulated <- data_manipulated %>%\n      mutate(name = forcats::fct_reorder(name, !! value_expr)) %>%\n      arrange(name)\n  }\n\n  if (fct_rev) {\n    data_manipulated <- data_manipulated %>%\n      mutate(name = forcats::fct_rev(name)) %>%\n      arrange(name)\n  }\n\n  # Visualization\n  g <- data_manipulated %>%\n\n        # \"name\" is a column name generated by our function internally as part of the data manipulation task\n        ggplot(aes(x = (!! value_expr), y = name)) +\n        geom_segment(aes(xend = 0, yend = name), color = color) +\n        geom_point(aes(size = !! value_expr), color = color) +\n        scale_x_continuous(labels = scales::dollar) +\n        scale_size(range = c(3, 5)) +\n        theme(legend.position = \"none\")\n\n  # Plot labels if TRUE\n  if (include_lbl) {\n    g <- g +\n      geom_label(aes(label = value_text, size = !! value_expr),\n                 hjust = \"inward\", color = color)\n  }\n\n  return(g)\n\n}\n\ndept_job_role_tbl %>%\n\n  # Block 1\n  count(Department, JobRole, Attrition) %>%\n\n  # Block 2\n  count_to_pct(Department, JobRole) %>%  \n\n  # Block 3\n  assess_attrition(Attrition, attrition_value = \"Yes\", baseline_pct = 0.088) %>%\n\n  # Block 4. Set salaray to 80000 for now\n  mutate(\n    cost_of_attrition = calculate_attrition_cost(n = n, salary = 80000)\n  ) %>%\n\n  # Select columnns\n  plot_attrition(Department, JobRole, .value = cost_of_attrition,\n                 units = \"M\") +\n  labs(\n    title = \"Estimated Cost of Attrition by Job Role\",\n    x = \"Cost of Attrition\",\n    subtitle = \"Looks like Sales Executive and Labaratory Technician are the biggest drivers of cost\"\n  )\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-5_2387c67df8528d7f78afd27e5dcfff28'}\n\n```{.r .cell-code}\n# Libraries \nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(skimr)\nlibrary(GGally)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n\n```{.r .cell-code}\n# Load Data data definitions\n\npath_data_definitions <- \"data_definitions.xlsx\"\ndefinitions_raw_tbl   <- read_excel(path_data_definitions, sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n```\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 35\n     Age Attrition BusinessTravel    DailyRate Department       DistanceFromHome\n   <dbl> <chr>     <chr>                 <dbl> <chr>                       <dbl>\n 1    41 Yes       Travel_Rarely          1102 Sales                           1\n 2    49 No        Travel_Frequently       279 Research & Deve~                8\n 3    37 Yes       Travel_Rarely          1373 Research & Deve~                2\n 4    33 No        Travel_Frequently      1392 Research & Deve~                3\n 5    27 No        Travel_Rarely           591 Research & Deve~                2\n 6    32 No        Travel_Frequently      1005 Research & Deve~                2\n 7    59 No        Travel_Rarely          1324 Research & Deve~                3\n 8    30 No        Travel_Rarely          1358 Research & Deve~               24\n 9    38 No        Travel_Frequently       216 Research & Deve~               23\n10    36 No        Travel_Rarely          1299 Research & Deve~               27\n# i 1,460 more rows\n# i 29 more variables: Education <dbl>, EducationField <chr>,\n#   EmployeeCount <dbl>, EmployeeNumber <dbl>, EnvironmentSatisfaction <dbl>,\n#   Gender <chr>, HourlyRate <dbl>, JobInvolvement <dbl>, JobLevel <dbl>,\n#   JobRole <chr>, JobSatisfaction <dbl>, MaritalStatus <chr>,\n#   MonthlyIncome <dbl>, MonthlyRate <dbl>, NumCompaniesWorked <dbl>,\n#   Over18 <chr>, OverTime <chr>, PercentSalaryHike <dbl>, ...\n```\n:::\n\n```{.r .cell-code}\n# Descriptive Features\nemployee_attrition_tbl %>% select(Age, DistanceFromHome, Gender, MaritalStatus, NumCompaniesWorked, Over18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 6\n     Age DistanceFromHome Gender MaritalStatus NumCompaniesWorked Over18\n   <dbl>            <dbl> <chr>  <chr>                      <dbl> <chr> \n 1    41                1 Female Single                         8 Y     \n 2    49                8 Male   Married                        1 Y     \n 3    37                2 Male   Single                         6 Y     \n 4    33                3 Female Married                        1 Y     \n 5    27                2 Male   Married                        9 Y     \n 6    32                2 Male   Single                         0 Y     \n 7    59                3 Female Married                        4 Y     \n 8    30               24 Male   Divorced                       1 Y     \n 9    38               23 Male   Single                         0 Y     \n10    36               27 Male   Married                        6 Y     \n# i 1,460 more rows\n```\n:::\n\n```{.r .cell-code}\n# Employment Features\nemployee_attrition_tbl %>% select(Department, EmployeeCount, EmployeeNumber, JobInvolvement, JobLevel, JobRole, JobSatisfaction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 7\n   Department       EmployeeCount EmployeeNumber JobInvolvement JobLevel JobRole\n   <chr>                    <dbl>          <dbl>          <dbl>    <dbl> <chr>  \n 1 Sales                        1              1              3        2 Sales ~\n 2 Research & Deve~             1              2              2        2 Resear~\n 3 Research & Deve~             1              4              2        1 Labora~\n 4 Research & Deve~             1              5              3        1 Resear~\n 5 Research & Deve~             1              7              3        1 Labora~\n 6 Research & Deve~             1              8              3        1 Labora~\n 7 Research & Deve~             1             10              4        1 Labora~\n 8 Research & Deve~             1             11              3        1 Labora~\n 9 Research & Deve~             1             12              2        3 Manufa~\n10 Research & Deve~             1             13              3        2 Health~\n# i 1,460 more rows\n# i 1 more variable: JobSatisfaction <dbl>\n```\n:::\n\n```{.r .cell-code}\n# Compensation Features\nemployee_attrition_tbl %>% select(DailyRate, HourlyRate, MonthlyIncome, MonthlyRate, PercentSalaryHike, StockOptionLevel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 6\n   DailyRate HourlyRate MonthlyIncome MonthlyRate PercentSalaryHike\n       <dbl>      <dbl>         <dbl>       <dbl>             <dbl>\n 1      1102         94          5993       19479                11\n 2       279         61          5130       24907                23\n 3      1373         92          2090        2396                15\n 4      1392         56          2909       23159                11\n 5       591         40          3468       16632                12\n 6      1005         79          3068       11864                13\n 7      1324         81          2670        9964                20\n 8      1358         67          2693       13335                22\n 9       216         44          9526        8787                21\n10      1299         94          5237       16577                13\n# i 1,460 more rows\n# i 1 more variable: StockOptionLevel <dbl>\n```\n:::\n\n```{.r .cell-code}\n# Survery Results\nemployee_attrition_tbl %>% select(EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction, WorkLifeBalance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 4\n   EnvironmentSatisfact~1 JobSatisfaction RelationshipSatisfac~2 WorkLifeBalance\n                    <dbl>           <dbl>                  <dbl>           <dbl>\n 1                      2               4                      1               1\n 2                      3               2                      4               3\n 3                      4               3                      2               3\n 4                      4               3                      3               3\n 5                      1               2                      4               3\n 6                      4               4                      3               2\n 7                      3               1                      1               2\n 8                      4               3                      2               3\n 9                      4               3                      2               3\n10                      3               3                      2               2\n# i 1,460 more rows\n# i abbreviated names: 1: EnvironmentSatisfaction, 2: RelationshipSatisfaction\n```\n:::\n\n```{.r .cell-code}\n# Performance Data\nemployee_attrition_tbl %>% select(JobInvolvement, PerformanceRating)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 2\n   JobInvolvement PerformanceRating\n            <dbl>             <dbl>\n 1              3                 3\n 2              2                 4\n 3              2                 3\n 4              3                 3\n 5              3                 3\n 6              3                 3\n 7              4                 4\n 8              3                 4\n 9              2                 4\n10              3                 3\n# i 1,460 more rows\n```\n:::\n\n```{.r .cell-code}\n# Work-Life Features\nemployee_attrition_tbl %>% select(BusinessTravel, OverTime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 2\n   BusinessTravel    OverTime\n   <chr>             <chr>   \n 1 Travel_Rarely     Yes     \n 2 Travel_Frequently No      \n 3 Travel_Rarely     Yes     \n 4 Travel_Frequently Yes     \n 5 Travel_Rarely     No      \n 6 Travel_Frequently No      \n 7 Travel_Rarely     Yes     \n 8 Travel_Rarely     No      \n 9 Travel_Frequently No      \n10 Travel_Rarely     No      \n# i 1,460 more rows\n```\n:::\n\n```{.r .cell-code}\n# Training & Education\nemployee_attrition_tbl %>% select(Education, EducationField, TrainingTimesLastYear)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 3\n   Education EducationField TrainingTimesLastYear\n       <dbl> <chr>                          <dbl>\n 1         2 Life Sciences                      0\n 2         1 Life Sciences                      3\n 3         2 Other                              3\n 4         4 Life Sciences                      3\n 5         1 Medical                            3\n 6         2 Life Sciences                      2\n 7         3 Medical                            3\n 8         1 Life Sciences                      2\n 9         3 Life Sciences                      2\n10         3 Medical                            3\n# i 1,460 more rows\n```\n:::\n\n```{.r .cell-code}\n# Time-Based Features\nemployee_attrition_tbl %>% select(TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 5\n   TotalWorkingYears YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion\n               <dbl>          <dbl>              <dbl>                   <dbl>\n 1                 8              6                  4                       0\n 2                10             10                  7                       1\n 3                 7              0                  0                       0\n 4                 8              8                  7                       3\n 5                 6              2                  2                       2\n 6                 8              7                  7                       3\n 7                12              1                  0                       0\n 8                 1              1                  0                       0\n 9                10              9                  7                       1\n10                17              7                  7                       7\n# i 1,460 more rows\n# i 1 more variable: YearsWithCurrManager <dbl>\n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-6_5c6c29a0effd3dad6b858067dfebf9e2'}\n\n```{.r .cell-code}\n# Step 1: Data Summarization -----\n\nskim(employee_attrition_tbl)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |                       |\n|:------------------------|:----------------------|\n|Name                     |employee_attrition_tbl |\n|Number of rows           |1470                   |\n|Number of columns        |35                     |\n|_______________________  |                       |\n|Column type frequency:   |                       |\n|character                |9                      |\n|numeric                  |26                     |\n|________________________ |                       |\n|Group variables          |None                   |\n\n\n**Variable type: character**\n\n|skim_variable  | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:--------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Attrition      |         0|             1|   2|   3|     0|        2|          0|\n|BusinessTravel |         0|             1|  10|  17|     0|        3|          0|\n|Department     |         0|             1|   5|  22|     0|        3|          0|\n|EducationField |         0|             1|   5|  16|     0|        6|          0|\n|Gender         |         0|             1|   4|   6|     0|        2|          0|\n|JobRole        |         0|             1|   7|  25|     0|        9|          0|\n|MaritalStatus  |         0|             1|   6|   8|     0|        3|          0|\n|Over18         |         0|             1|   1|   1|     0|        1|          0|\n|OverTime       |         0|             1|   2|   3|     0|        2|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable            | n_missing| complete_rate|     mean|      sd|   p0|     p25|     p50|      p75|  p100|hist                                     |\n|:------------------------|---------:|-------------:|--------:|-------:|----:|-------:|-------:|--------:|-----:|:----------------------------------------|\n|Age                      |         0|             1|    36.92|    9.14|   18|   30.00|    36.0|    43.00|    60|▂▇▇▃▂ |\n|DailyRate                |         0|             1|   802.49|  403.51|  102|  465.00|   802.0|  1157.00|  1499|▇▇▇▇▇ |\n|DistanceFromHome         |         0|             1|     9.19|    8.11|    1|    2.00|     7.0|    14.00|    29|▇▅▂▂▂ |\n|Education                |         0|             1|     2.91|    1.02|    1|    2.00|     3.0|     4.00|     5|▂▃▇▆▁ |\n|EmployeeCount            |         0|             1|     1.00|    0.00|    1|    1.00|     1.0|     1.00|     1|▁▁▇▁▁ |\n|EmployeeNumber           |         0|             1|  1024.87|  602.02|    1|  491.25|  1020.5|  1555.75|  2068|▇▇▇▇▇ |\n|EnvironmentSatisfaction  |         0|             1|     2.72|    1.09|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|HourlyRate               |         0|             1|    65.89|   20.33|   30|   48.00|    66.0|    83.75|   100|▇▇▇▇▇ |\n|JobInvolvement           |         0|             1|     2.73|    0.71|    1|    2.00|     3.0|     3.00|     4|▁▃▁▇▁ |\n|JobLevel                 |         0|             1|     2.06|    1.11|    1|    1.00|     2.0|     3.00|     5|▇▇▃▂▁ |\n|JobSatisfaction          |         0|             1|     2.73|    1.10|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|MonthlyIncome            |         0|             1|  6502.93| 4707.96| 1009| 2911.00|  4919.0|  8379.00| 19999|▇▅▂▁▂ |\n|MonthlyRate              |         0|             1| 14313.10| 7117.79| 2094| 8047.00| 14235.5| 20461.50| 26999|▇▇▇▇▇ |\n|NumCompaniesWorked       |         0|             1|     2.69|    2.50|    0|    1.00|     2.0|     4.00|     9|▇▃▂▂▁ |\n|PercentSalaryHike        |         0|             1|    15.21|    3.66|   11|   12.00|    14.0|    18.00|    25|▇▅▃▂▁ |\n|PerformanceRating        |         0|             1|     3.15|    0.36|    3|    3.00|     3.0|     3.00|     4|▇▁▁▁▂ |\n|RelationshipSatisfaction |         0|             1|     2.71|    1.08|    1|    2.00|     3.0|     4.00|     4|▅▅▁▇▇ |\n|StandardHours            |         0|             1|    80.00|    0.00|   80|   80.00|    80.0|    80.00|    80|▁▁▇▁▁ |\n|StockOptionLevel         |         0|             1|     0.79|    0.85|    0|    0.00|     1.0|     1.00|     3|▇▇▁▂▁ |\n|TotalWorkingYears        |         0|             1|    11.28|    7.78|    0|    6.00|    10.0|    15.00|    40|▇▇▂▁▁ |\n|TrainingTimesLastYear    |         0|             1|     2.80|    1.29|    0|    2.00|     3.0|     3.00|     6|▂▇▇▂▃ |\n|WorkLifeBalance          |         0|             1|     2.76|    0.71|    1|    2.00|     3.0|     3.00|     4|▁▃▁▇▂ |\n|YearsAtCompany           |         0|             1|     7.01|    6.13|    0|    3.00|     5.0|     9.00|    40|▇▂▁▁▁ |\n|YearsInCurrentRole       |         0|             1|     4.23|    3.62|    0|    2.00|     3.0|     7.00|    18|▇▃▂▁▁ |\n|YearsSinceLastPromotion  |         0|             1|     2.19|    3.22|    0|    0.00|     1.0|     3.00|    15|▇▁▁▁▁ |\n|YearsWithCurrManager     |         0|             1|     4.12|    3.57|    0|    2.00|     3.0|     7.00|    17|▇▂▅▁▁ |\n:::\n\n```{.r .cell-code}\n# Character Data Type\nemployee_attrition_tbl %>%\n    select_if(is.character) %>%\n    glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,470\nColumns: 9\n$ Attrition      <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\",~\n$ BusinessTravel <chr> \"Travel_Rarely\", \"Travel_Frequently\", \"Travel_Rarely\", ~\n$ Department     <chr> \"Sales\", \"Research & Development\", \"Research & Developm~\n$ EducationField <chr> \"Life Sciences\", \"Life Sciences\", \"Other\", \"Life Scienc~\n$ Gender         <chr> \"Female\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\", \"Fe~\n$ JobRole        <chr> \"Sales Executive\", \"Research Scientist\", \"Laboratory Te~\n$ MaritalStatus  <chr> \"Single\", \"Married\", \"Single\", \"Married\", \"Married\", \"S~\n$ Over18         <chr> \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", ~\n$ OverTime       <chr> \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No~\n```\n:::\n\n```{.r .cell-code}\n# Get \"levels\"\nemployee_attrition_tbl %>%\n    select_if(is.character) %>%\n    map(unique)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Attrition\n[1] \"Yes\" \"No\" \n\n$BusinessTravel\n[1] \"Travel_Rarely\"     \"Travel_Frequently\" \"Non-Travel\"       \n\n$Department\n[1] \"Sales\"                  \"Research & Development\" \"Human Resources\"       \n\n$EducationField\n[1] \"Life Sciences\"    \"Other\"            \"Medical\"          \"Marketing\"       \n[5] \"Technical Degree\" \"Human Resources\" \n\n$Gender\n[1] \"Female\" \"Male\"  \n\n$JobRole\n[1] \"Sales Executive\"           \"Research Scientist\"       \n[3] \"Laboratory Technician\"     \"Manufacturing Director\"   \n[5] \"Healthcare Representative\" \"Manager\"                  \n[7] \"Sales Representative\"      \"Research Director\"        \n[9] \"Human Resources\"          \n\n$MaritalStatus\n[1] \"Single\"   \"Married\"  \"Divorced\"\n\n$Over18\n[1] \"Y\"\n\n$OverTime\n[1] \"Yes\" \"No\" \n```\n:::\n\n```{.r .cell-code}\n# Proportions    \nemployee_attrition_tbl %>%\n    select_if(is.character) %>%\n    map(~ table(.) %>% prop.table())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Attrition\n.\n       No       Yes \n0.8387755 0.1612245 \n\n$BusinessTravel\n.\n       Non-Travel Travel_Frequently     Travel_Rarely \n        0.1020408         0.1884354         0.7095238 \n\n$Department\n.\n       Human Resources Research & Development                  Sales \n            0.04285714             0.65374150             0.30340136 \n\n$EducationField\n.\n Human Resources    Life Sciences        Marketing          Medical \n      0.01836735       0.41224490       0.10816327       0.31564626 \n           Other Technical Degree \n      0.05578231       0.08979592 \n\n$Gender\n.\nFemale   Male \n   0.4    0.6 \n\n$JobRole\n.\nHealthcare Representative           Human Resources     Laboratory Technician \n               0.08911565                0.03537415                0.17619048 \n                  Manager    Manufacturing Director         Research Director \n               0.06938776                0.09863946                0.05442177 \n       Research Scientist           Sales Executive      Sales Representative \n               0.19863946                0.22176871                0.05646259 \n\n$MaritalStatus\n.\n Divorced   Married    Single \n0.2224490 0.4578231 0.3197279 \n\n$Over18\n.\nY \n1 \n\n$OverTime\n.\n       No       Yes \n0.7170068 0.2829932 \n```\n:::\n\n```{.r .cell-code}\n# Numeric Data\nemployee_attrition_tbl %>%\n    select_if(is.numeric) %>%\n    map(~ unique(.) %>% length())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Age\n[1] 43\n\n$DailyRate\n[1] 886\n\n$DistanceFromHome\n[1] 29\n\n$Education\n[1] 5\n\n$EmployeeCount\n[1] 1\n\n$EmployeeNumber\n[1] 1470\n\n$EnvironmentSatisfaction\n[1] 4\n\n$HourlyRate\n[1] 71\n\n$JobInvolvement\n[1] 4\n\n$JobLevel\n[1] 5\n\n$JobSatisfaction\n[1] 4\n\n$MonthlyIncome\n[1] 1349\n\n$MonthlyRate\n[1] 1427\n\n$NumCompaniesWorked\n[1] 10\n\n$PercentSalaryHike\n[1] 15\n\n$PerformanceRating\n[1] 2\n\n$RelationshipSatisfaction\n[1] 4\n\n$StandardHours\n[1] 1\n\n$StockOptionLevel\n[1] 4\n\n$TotalWorkingYears\n[1] 40\n\n$TrainingTimesLastYear\n[1] 7\n\n$WorkLifeBalance\n[1] 4\n\n$YearsAtCompany\n[1] 37\n\n$YearsInCurrentRole\n[1] 19\n\n$YearsSinceLastPromotion\n[1] 16\n\n$YearsWithCurrManager\n[1] 18\n```\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl %>%\n    select_if(is.numeric) %>%\n    map_df(~ unique(.) %>% length()) %>%\n    # Select all columns\n    pivot_longer(everything()) %>%\n    arrange(value) %>%\n    filter(value <= 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 x 2\n   name                     value\n   <chr>                    <int>\n 1 EmployeeCount                1\n 2 StandardHours                1\n 3 PerformanceRating            2\n 4 EnvironmentSatisfaction      4\n 5 JobInvolvement               4\n 6 JobSatisfaction              4\n 7 RelationshipSatisfaction     4\n 8 StockOptionLevel             4\n 9 WorkLifeBalance              4\n10 Education                    5\n11 JobLevel                     5\n12 TrainingTimesLastYear        7\n13 NumCompaniesWorked          10\n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-7_656ed411c78524eeaa2f1773243816e5'}\n\n```{.r .cell-code}\nlibrary(GGally)\n# Step 2: Data Visualization ----\n\n# Create data tibble, to potentially debug the plot_ggpairs function (because it has a data argument)\ndata <- employee_attrition_tbl %>%\n    select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome)\n\nplot_ggpairs <- function(data, color = NULL, density_alpha = 0.5) {\n    \n    color_expr <- enquo(color)\n    \n    if (rlang::quo_is_null(color_expr)) {\n        \n        g <- data %>%\n            ggpairs(lower = \"blank\") \n        \n    } else {\n        \n        color_name <- quo_name(color_expr)\n        \n        g <- data %>%\n            ggpairs(mapping = aes_string(color = color_name), \n                    lower = \"blank\", legend = 1,\n                    diag = list(continuous = wrap(\"densityDiag\", \n                                                  alpha = density_alpha))) +\n            theme(legend.position = \"bottom\")\n    }\n    \n    return(g)\n    \n}\n\nemployee_attrition_tbl %>%\n    select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %>%\n    plot_ggpairs(color = Attrition)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\ni Please use tidy evaluation idioms with `aes()`.\ni See also `vignette(\"ggplot2-in-packages\")` for more information.\n```\n:::\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-8_ed65f70aef6728e25f9f1c152b265756'}\n\n```{.r .cell-code}\n# Explore Features by Category\n\n#   1. Descriptive features: age, gender, marital status \nemployee_attrition_tbl %>%\n    select(Attrition, Age, Gender, MaritalStatus, NumCompaniesWorked, Over18, DistanceFromHome) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#   2. Employment features: department, job role, job level\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"employee\"), contains(\"department\"), contains(\"job\")) %>%\n    plot_ggpairs(Attrition) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n\nWarning in cor(x, y): Standardabweichung ist Null\n```\n:::\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#   3. Compensation features: HourlyRate, MonthlyIncome, StockOptionLevel \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"income\"), contains(\"rate\"), contains(\"salary\"), contains(\"stock\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#   4. Survey Results: Satisfaction level, WorkLifeBalance \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"satisfaction\"), contains(\"life\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#   5. Performance Data: Job Involvment, Performance Rating\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"performance\"), contains(\"involvement\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-5.png){width=672}\n:::\n\n```{.r .cell-code}\n#   6. Work-Life Features \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"overtime\"), contains(\"travel\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-6.png){width=672}\n:::\n\n```{.r .cell-code}\n#   7. Training and Education \nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"training\"), contains(\"education\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-7.png){width=672}\n:::\n\n```{.r .cell-code}\n#   8. Time-Based Features: Years at company, years in current role\nemployee_attrition_tbl %>%\n    select(Attrition, contains(\"years\")) %>%\n    plot_ggpairs(Attrition)\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-8-8.png){width=672}\n:::\n:::\n\n\n\n# Challenge (Part I)\n## Question 1 | What can you deduce about the interaction between Monthly Income and Attrition?\n| There is a big spike of people having attrition at the low end of the monthly income spectrum far greater than people having no attrition with low monthly income. This indicates that monthly income has a relatively strong affect on attrition.\n## Question 2 | What can you deduce about the interaction between Percent Salary Hike and Attrition?\n| The attrition graph depending on the percent salary hike is nearly identical for people with attrition and without. Meaning a percent salary hike has very little effect on attrition.\n## Question 3 | What can you deduce about the interaction between Stock Option Level and Attrition?\n| The attrition vs. stock option level graph shows that people having a stock option level of 1 or to a lesser extend 2 are much less likely to have high attrition, meaning there could be a positive effect between the stock option level and attrition for the employer.\n## Question 4 | What can you deduce about the interaction between Environment Satisfaction and Attrition?\n| First of all, the satisfaction levels of the survey seemed to be clumped in certain levels which is likely the result of some kind of numerical scale being used for this survey (Rate from 1 to 4 for example). Considering that, there is an upward trend in the number of people having no attrition with higher satisfaction.\n## Question 5 | What can you deduce about the interaction between Work Life Balance and Attrition\n| The work life balance seems to indicate a stronger connection with attrition, with people rating their work life balance more positively having less attrition.\n## Question 6 | What Can you deduce about the interaction between Job Involvement and Attrition?\n| People that are more involved in the job are less likely to have attrition.\n## Question 7 | What can you deduce about the interaction between Over Time and Attrition?\n| Roughly the same amount of people that have attrition do and do not perform overtime. But as a percentage, the people doing overtime are much more likely to have attrition.\n## Question 8 | What can you deduce about the interaction between Training Times Last Year and Attrition\n| There is a slight trend, that more training time results in less attrition but as far as I can tell very minor.\n## Question 9 | What can you deduce about the interaction between Years At Company and Attrition\n| Regarding years at the company for very new people the attrition is much higher than for those that are very long with the company.\n| Crucially those that stay long have very low attrition, since most likely those with high attrition left at some point, so the data is inherently somewhat skewed.\n## Question 10 | What can you deduce about the interaction between Years Since Last Promotion and Attrition?\n| Years since last promotion seem to have a rather small affect on attrition but the small bump in attrition if people are longer with the company is noteworthy, meaning that people that stayed with the company for an extended amount of time without a promotion start to get more attrition.\n\n# Business case (Part II)\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-9_45cb5b604a5aefeae383fa90771a2b49'}\n\n```{.r .cell-code}\n# Load data\nlibrary(tidyverse)\nlibrary(readxl)\n\nemployee_attrition_tbl <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1470 Columns: 35\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\ndbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndefinitions_raw_tbl    <- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n```\n:::\n\n```{.r .cell-code}\n#View(definitions_raw_tbl)\n\nemployee_attrition_tbl %>% \n        ggplot(aes(Education)) +\n        geom_bar()\n```\n\n::: {.cell-output-display}\n![](03_automated_maschine_learning_with_H2O_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Data preparation ----\n# Human readable\n\ndefinitions_tbl <- definitions_raw_tbl %>% \n  fill(...1, .direction = \"down\") %>%\n  filter(!is.na(...2)) %>%\n  separate(...2, into = c(\"key\", \"value\"), sep = \" '\", remove = TRUE) %>%\n  rename(column_name = ...1) %>%\n  mutate(key = as.numeric(key)) %>%\n  mutate(value = value %>% str_replace(pattern = \"'\", replacement = \"\")) \ndefinitions_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 x 3\n   column_name               key value        \n   <chr>                   <dbl> <chr>        \n 1 Education                   1 Below College\n 2 Education                   2 College      \n 3 Education                   3 Bachelor     \n 4 Education                   4 Master       \n 5 Education                   5 Doctor       \n 6 EnvironmentSatisfaction     1 Low          \n 7 EnvironmentSatisfaction     2 Medium       \n 8 EnvironmentSatisfaction     3 High         \n 9 EnvironmentSatisfaction     4 Very High    \n10 JobInvolvement              1 Low          \n# i 19 more rows\n```\n:::\n\n```{.r .cell-code}\ndefinitions_list <- definitions_tbl %>% \n  \n  # Mapping over lists\n  \n  # Split into multiple tibbles\n  split(.$column_name) %>%\n  # Remove column_name\n  map(~ select(., -column_name)) %>%\n  # Convert to factors because they are ordered an we want to maintain that order\n  map(~ mutate(., value = as_factor(value)))\n\nfor (i in seq_along(definitions_list)) {\n  list_name <- names(definitions_list)[i]\n  colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, \"_value\"))\n}\n\ndefinitions_list[[\"Education\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  Education Education_value\n      <dbl> <fct>          \n1         1 Below College  \n2         2 College        \n3         3 Bachelor       \n4         4 Master         \n5         5 Doctor         \n```\n:::\n\n```{.r .cell-code}\ndata_merged_tbl <- list(HR_Data = employee_attrition_tbl) %>%\n    \n        # Join everything\n        append(definitions_list, after = 1) %>%\n        reduce(left_join) %>%\n        \n        # Remove unnecessary columns\n        select(-one_of(names(definitions_list))) %>%\n        \n        # Format the \"_value\"\n        set_names(str_replace_all(names(.), pattern = \"_value\", replacement = \"\")) %>%\n        \n        # Resort\n        select(sort(names(.)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Education)`\nJoining with `by = join_by(EnvironmentSatisfaction)`\nJoining with `by = join_by(JobInvolvement)`\nJoining with `by = join_by(JobSatisfaction)`\nJoining with `by = join_by(PerformanceRating)`\nJoining with `by = join_by(RelationshipSatisfaction)`\nJoining with `by = join_by(WorkLifeBalance)`\n```\n:::\n\n```{.r .cell-code}\ndata_merged_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,470 x 35\n     Age Attrition BusinessTravel    DailyRate Department       DistanceFromHome\n   <dbl> <chr>     <chr>                 <dbl> <chr>                       <dbl>\n 1    41 Yes       Travel_Rarely          1102 Sales                           1\n 2    49 No        Travel_Frequently       279 Research & Deve~                8\n 3    37 Yes       Travel_Rarely          1373 Research & Deve~                2\n 4    33 No        Travel_Frequently      1392 Research & Deve~                3\n 5    27 No        Travel_Rarely           591 Research & Deve~                2\n 6    32 No        Travel_Frequently      1005 Research & Deve~                2\n 7    59 No        Travel_Rarely          1324 Research & Deve~                3\n 8    30 No        Travel_Rarely          1358 Research & Deve~               24\n 9    38 No        Travel_Frequently       216 Research & Deve~               23\n10    36 No        Travel_Rarely          1299 Research & Deve~               27\n# i 1,460 more rows\n# i 29 more variables: Education <fct>, EducationField <chr>,\n#   EmployeeCount <dbl>, EmployeeNumber <dbl>, EnvironmentSatisfaction <fct>,\n#   Gender <chr>, HourlyRate <dbl>, JobInvolvement <fct>, JobLevel <dbl>,\n#   JobRole <chr>, JobSatisfaction <fct>, MaritalStatus <chr>,\n#   MonthlyIncome <dbl>, MonthlyRate <dbl>, NumCompaniesWorked <dbl>,\n#   Over18 <chr>, OverTime <chr>, PercentSalaryHike <dbl>, ...\n```\n:::\n\n```{.r .cell-code}\n# Return only unique values of BusinessTravel\ndata_merged_tbl %>% \n  distinct(BusinessTravel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 1\n  BusinessTravel   \n  <chr>            \n1 Travel_Rarely    \n2 Travel_Frequently\n3 Non-Travel       \n```\n:::\n\n```{.r .cell-code}\ndata_merged_tbl %>%\n        mutate_if(is.character, as.factor) %>%\n        glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,470\nColumns: 35\n$ Age                      <dbl> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2~\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,~\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare~\n$ DailyRate                <dbl> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,~\n$ Department               <fct> Sales, Research & Development, Research & Dev~\n$ DistanceFromHome         <dbl> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, ~\n$ Education                <fct> College, Below College, College, Master, Belo~\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci~\n$ EmployeeCount            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ EmployeeNumber           <dbl> 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,~\n$ EnvironmentSatisfaction  <fct> Medium, High, Very High, Very High, Low, Very~\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal~\n$ HourlyRate               <dbl> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4~\n$ JobInvolvement           <fct> High, Medium, Medium, High, High, High, Very ~\n$ JobLevel                 <dbl> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, ~\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato~\n$ JobSatisfaction          <fct> Very High, Medium, High, High, Medium, Very H~\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si~\n$ MonthlyIncome            <dbl> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269~\n$ MonthlyRate              <dbl> 19479, 24907, 2396, 23159, 16632, 11864, 9964~\n$ NumCompaniesWorked       <dbl> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, ~\n$ Over18                   <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, ~\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N~\n$ PercentSalaryHike        <dbl> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1~\n$ PerformanceRating        <fct> Excellent, Outstanding, Excellent, Excellent,~\n$ RelationshipSatisfaction <fct> Low, Very High, Medium, High, Very High, High~\n$ StandardHours            <dbl> 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 8~\n$ StockOptionLevel         <dbl> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, ~\n$ TotalWorkingYears        <dbl> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3~\n$ TrainingTimesLastYear    <dbl> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, ~\n$ WorkLifeBalance          <fct> Bad, Better, Better, Better, Better, Good, Go~\n$ YearsAtCompany           <dbl> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,~\n$ YearsInCurrentRole       <dbl> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, ~\n$ YearsSinceLastPromotion  <dbl> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, ~\n$ YearsWithCurrManager     <dbl> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, ~\n```\n:::\n\n```{.r .cell-code}\ndata_processed_tbl <- data_merged_tbl %>%        \n        mutate_if(is.character, as.factor) %>%\n        mutate(\n            BusinessTravel = BusinessTravel %>% fct_relevel(\"Non-Travel\", \n                                                            \"Travel_Rarely\", \n                                                            \"Travel_Frequently\"),\n            MaritalStatus  = MaritalStatus %>% fct_relevel(\"Single\", \n                                                           \"Married\", \n                                                           \"Divorced\")\n        )\n        \ndata_processed_tbl %>% \n  select_if(is.factor) %>% \n  map(levels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Attrition\n[1] \"No\"  \"Yes\"\n\n$BusinessTravel\n[1] \"Non-Travel\"        \"Travel_Rarely\"     \"Travel_Frequently\"\n\n$Department\n[1] \"Human Resources\"        \"Research & Development\" \"Sales\"                 \n\n$Education\n[1] \"Below College\" \"College\"       \"Bachelor\"      \"Master\"       \n[5] \"Doctor\"       \n\n$EducationField\n[1] \"Human Resources\"  \"Life Sciences\"    \"Marketing\"        \"Medical\"         \n[5] \"Other\"            \"Technical Degree\"\n\n$EnvironmentSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$Gender\n[1] \"Female\" \"Male\"  \n\n$JobInvolvement\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$JobRole\n[1] \"Healthcare Representative\" \"Human Resources\"          \n[3] \"Laboratory Technician\"     \"Manager\"                  \n[5] \"Manufacturing Director\"    \"Research Director\"        \n[7] \"Research Scientist\"        \"Sales Executive\"          \n[9] \"Sales Representative\"     \n\n$JobSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$MaritalStatus\n[1] \"Single\"   \"Married\"  \"Divorced\"\n\n$Over18\n[1] \"Y\"\n\n$OverTime\n[1] \"No\"  \"Yes\"\n\n$PerformanceRating\n[1] \"Low\"         \"Good\"        \"Excellent\"   \"Outstanding\"\n\n$RelationshipSatisfaction\n[1] \"Low\"       \"Medium\"    \"High\"      \"Very High\"\n\n$WorkLifeBalance\n[1] \"Bad\"    \"Good\"   \"Better\" \"Best\"  \n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-10_5f1981fa242abb16301dc18c111191b0'}\n\n```{.r .cell-code}\nprocess_hr_data_readable <- function(data, definitions_tbl) {\n\n    definitions_list <- definitions_tbl %>%\n        fill(...1, .direction = \"down\") %>%\n        filter(!is.na(...2)) %>%\n        separate(...2, into = c(\"key\", \"value\"), sep = \" '\", remove = TRUE) %>%\n        rename(column_name = ...1) %>%\n        mutate(key = as.numeric(key)) %>%\n        mutate(value = value %>% str_replace(pattern = \"'\", replacement = \"\")) %>%\n        split(.$column_name) %>%\n        map(~ select(., -column_name)) %>%\n        map(~ mutate(., value = as_factor(value))) \n    \n    for (i in seq_along(definitions_list)) {\n        list_name <- names(definitions_list)[i]\n        colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, \"_value\"))\n    }\n    \n    data_merged_tbl <- list(HR_Data = data) %>%\n        append(definitions_list, after = 1) %>%\n        reduce(left_join) %>%\n        select(-one_of(names(definitions_list))) %>%\n        set_names(str_replace_all(names(.), pattern = \"_value\", \n                                            replacement = \"\")) %>%\n        select(sort(names(.))) %>%\n        mutate_if(is.character, as.factor) %>%\n        mutate(\n            BusinessTravel = BusinessTravel %>% fct_relevel(\"Non-Travel\", \n                                                            \"Travel_Rarely\", \n                                                            \"Travel_Frequently\"),\n            MaritalStatus  = MaritalStatus %>% fct_relevel(\"Single\", \n                                                           \"Married\", \n                                                           \"Divorced\")\n        )\n    \n    return(data_merged_tbl)\n    \n}\nprocess_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl) %>% \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Education)`\nJoining with `by = join_by(EnvironmentSatisfaction)`\nJoining with `by = join_by(JobInvolvement)`\nJoining with `by = join_by(JobSatisfaction)`\nJoining with `by = join_by(PerformanceRating)`\nJoining with `by = join_by(RelationshipSatisfaction)`\nJoining with `by = join_by(WorkLifeBalance)`\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,470\nColumns: 35\n$ Age                      <dbl> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2~\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,~\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare~\n$ DailyRate                <dbl> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,~\n$ Department               <fct> Sales, Research & Development, Research & Dev~\n$ DistanceFromHome         <dbl> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, ~\n$ Education                <fct> College, Below College, College, Master, Belo~\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci~\n$ EmployeeCount            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ EmployeeNumber           <dbl> 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,~\n$ EnvironmentSatisfaction  <fct> Medium, High, Very High, Very High, Low, Very~\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal~\n$ HourlyRate               <dbl> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4~\n$ JobInvolvement           <fct> High, Medium, Medium, High, High, High, Very ~\n$ JobLevel                 <dbl> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, ~\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato~\n$ JobSatisfaction          <fct> Very High, Medium, High, High, Medium, Very H~\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si~\n$ MonthlyIncome            <dbl> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269~\n$ MonthlyRate              <dbl> 19479, 24907, 2396, 23159, 16632, 11864, 9964~\n$ NumCompaniesWorked       <dbl> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, ~\n$ Over18                   <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, ~\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N~\n$ PercentSalaryHike        <dbl> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1~\n$ PerformanceRating        <fct> Excellent, Outstanding, Excellent, Excellent,~\n$ RelationshipSatisfaction <fct> Low, Very High, Medium, High, Very High, High~\n$ StandardHours            <dbl> 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 8~\n$ StockOptionLevel         <dbl> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, ~\n$ TotalWorkingYears        <dbl> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3~\n$ TrainingTimesLastYear    <dbl> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, ~\n$ WorkLifeBalance          <fct> Bad, Better, Better, Better, Better, Good, Go~\n$ YearsAtCompany           <dbl> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,~\n$ YearsInCurrentRole       <dbl> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, ~\n$ YearsSinceLastPromotion  <dbl> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, ~\n$ YearsWithCurrManager     <dbl> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, ~\n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-11_17efcd33e9d0595e63294047e1763593'}\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'recipes'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stringr':\n\n    fixed\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nemployee_attrition_tbl          <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1470 Columns: 35\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\ndbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndefinitions_raw_tbl             <- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n```\n:::\n\n```{.r .cell-code}\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Education)`\nJoining with `by = join_by(EnvironmentSatisfaction)`\nJoining with `by = join_by(JobInvolvement)`\nJoining with `by = join_by(JobSatisfaction)`\nJoining with `by = join_by(PerformanceRating)`\nJoining with `by = join_by(RelationshipSatisfaction)`\nJoining with `by = join_by(WorkLifeBalance)`\n```\n:::\n\n```{.r .cell-code}\nset.seed(seed = 1113)\nsplit_obj                       <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\ntrain_readable_tbl              <- training(split_obj)\ntest_readable_tbl               <- testing(split_obj)\n\nrecipe_obj <- recipe(Attrition ~., data = train_readable_tbl) %>% \n    step_zv(all_predictors()) %>% \n    step_mutate_at(JobLevel, StockOptionLevel, fn = as.factor) %>% \n    prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# Modeling\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 hours 41 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.40.0.1 \n    H2O cluster version age:    3 months and 11 days \n    H2O cluster name:           H2O_started_from_R_Chris_yuh446 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.42 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.0.5 (2021-03-31) \n```\n:::\n\n```{.r .cell-code}\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"Attrition\"\nx <- setdiff(names(train_h2o), y)\n\n# ?h2o.automl\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |====                                                                  |   6%\n16:06:39.267: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n16:06:39.269: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-12_d70a8dd8f2db5fd5437fdf385cbba9aa'}\n\n```{.r .cell-code}\ntypeof(automl_models_h2o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"S4\"\n```\n:::\n\n```{.r .cell-code}\nslotNames(automl_models_h2o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"     \n[5] \"modeling_steps\" \"training_info\" \n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                  model_id       auc   logloss\n1             GBM_grid_1_AutoML_12_20230520_160639_model_7 0.8696713 0.3582326\n2 StackedEnsemble_BestOfFamily_5_AutoML_12_20230520_160639 0.8637648 0.3358554\n3 StackedEnsemble_BestOfFamily_4_AutoML_12_20230520_160639 0.8615819 0.3397077\n4 StackedEnsemble_BestOfFamily_2_AutoML_12_20230520_160639 0.8614535 0.3432543\n5    StackedEnsemble_AllModels_1_AutoML_12_20230520_160639 0.8606831 0.3441091\n6 StackedEnsemble_BestOfFamily_3_AutoML_12_20230520_160639 0.8604263 0.3425616\n      aucpr mean_per_class_error      rmse        mse\n1 0.7001650            0.2555855 0.3337552 0.11139251\n2 0.7248473            0.2243195 0.3160107 0.09986277\n3 0.7209287            0.2243195 0.3180124 0.10113192\n4 0.7172839            0.2299692 0.3194663 0.10205870\n5 0.7155361            0.2299692 0.3201903 0.10252185\n6 0.7197116            0.2299692 0.3181193 0.10119988\n\n[43 rows x 7 columns] \n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leader\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: gbm\nModel ID:  GBM_grid_1_AutoML_12_20230520_160639_model_7 \nModel Summary: \n  number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n1              49                       49                7652         3\n  max_depth mean_depth min_leaves max_leaves mean_leaves\n1         3    3.00000          7          8     7.79592\n\n\nH2OBinomialMetrics: gbm\n** Reported on training data. **\n\nMSE:  0.06050782\nRMSE:  0.2459834\nLogLoss:  0.2190137\nMean Per-Class Error:  0.1272047\nAUC:  0.952312\nAUCPR:  0.8568108\nGini:  0.904624\nR^2:  0.5138176\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error      Rate\nNo     883  26 0.028603   =26/909\nYes     35 120 0.225806   =35/155\nTotals 918 146 0.057331  =61/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.295844   0.797342 123\n2                       max f2  0.203883   0.802696 155\n3                 max f0point5  0.329361   0.839580 109\n4                 max accuracy  0.329361   0.944549 109\n5                max precision  0.912383   1.000000   0\n6                   max recall  0.036350   1.000000 360\n7              max specificity  0.912383   1.000000   0\n8             max absolute_mcc  0.322060   0.765901 112\n9   max min_per_class_accuracy  0.159277   0.872387 187\n10 max mean_per_class_accuracy  0.203883   0.886827 155\n11                     max tns  0.912383 909.000000   0\n12                     max fns  0.912383 154.000000   0\n13                     max fps  0.012478 909.000000 399\n14                     max tps  0.036350 155.000000 360\n15                     max tnr  0.912383   1.000000   0\n16                     max fnr  0.912383   0.993548   0\n17                     max fpr  0.012478   1.000000 399\n18                     max tpr  0.036350   1.000000 360\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: gbm\n** Reported on validation data. **\n\nMSE:  0.123212\nRMSE:  0.3510156\nLogLoss:  0.3882511\nMean Per-Class Error:  0.2438238\nAUC:  0.8320802\nAUCPR:  0.6112766\nGini:  0.6641604\nR^2:  0.2450897\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error     Rate\nNo     114  33 0.224490  =33/147\nYes     10  28 0.263158   =10/38\nTotals 124  61 0.232432  =43/185\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.150515   0.565657  60\n2                       max f2  0.102291   0.723140  89\n3                 max f0point5  0.554050   0.608108   8\n4                 max accuracy  0.554050   0.843243   8\n5                max precision  0.899038   1.000000   0\n6                   max recall  0.047906   1.000000 138\n7              max specificity  0.899038   1.000000   0\n8             max absolute_mcc  0.109157   0.450019  83\n9   max min_per_class_accuracy  0.150515   0.736842  60\n10 max mean_per_class_accuracy  0.109157   0.777300  83\n11                     max tns  0.899038 147.000000   0\n12                     max fns  0.899038  37.000000   0\n13                     max fps  0.014998 147.000000 184\n14                     max tps  0.047906  38.000000 138\n15                     max tnr  0.899038   1.000000   0\n16                     max fnr  0.899038   0.973684   0\n17                     max fpr  0.014998   1.000000 184\n18                     max tpr  0.047906   1.000000 138\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: gbm\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.09794426\nRMSE:  0.3129605\nLogLoss:  0.330732\nMean Per-Class Error:  0.2654565\nAUC:  0.796799\nAUCPR:  0.5077129\nGini:  0.5935981\nR^2:  0.2130146\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error       Rate\nNo     790 119 0.130913   =119/909\nYes     62  93 0.400000    =62/155\nTotals 852 212 0.170113  =181/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.195867   0.506812 151\n2                       max f2  0.147207   0.598706 195\n3                 max f0point5  0.263669   0.513748  99\n4                 max accuracy  0.557146   0.875000  25\n5                max precision  0.946412   1.000000   0\n6                   max recall  0.017638   1.000000 390\n7              max specificity  0.946412   1.000000   0\n8             max absolute_mcc  0.182315   0.414373 163\n9   max min_per_class_accuracy  0.132363   0.729032 212\n10 max mean_per_class_accuracy  0.147207   0.750254 195\n11                     max tns  0.946412 909.000000   0\n12                     max fns  0.946412 154.000000   0\n13                     max fps  0.009729 909.000000 399\n14                     max tps  0.017638 155.000000 390\n15                     max tnr  0.946412   1.000000   0\n16                     max fnr  0.946412   0.993548   0\n17                     max fpr  0.009729   1.000000 399\n18                     max tpr  0.017638   1.000000 390\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n                             mean       sd cv_1_valid cv_2_valid cv_3_valid\naccuracy                 0.838391 0.044715   0.774648   0.863850   0.812207\nauc                      0.789872 0.045835   0.728448   0.842754   0.776536\nerr                      0.161609 0.044715   0.225352   0.136150   0.187793\nerr_count               34.400000 9.555103  48.000000  29.000000  40.000000\nf0point5                 0.494950 0.090521   0.352697   0.572289   0.464602\nf1                       0.528944 0.071294   0.414634   0.567164   0.512195\nf2                       0.572092 0.048655   0.502959   0.562130   0.570652\nlift_top_group           6.429757 1.074968   4.896552   6.264706   6.264706\nlogloss                  0.332419 0.033242   0.356348   0.319605   0.365312\nmax_per_class_error      0.391551 0.040159   0.413793   0.441176   0.382353\nmcc                      0.442474 0.087369   0.309807   0.486482   0.409207\nmean_per_class_accuracy  0.743207 0.035294   0.695277   0.740306   0.733405\nmean_per_class_error     0.256793 0.035294   0.304723   0.259694   0.266595\nmse                      0.098348 0.011212   0.106450   0.096924   0.109705\npr_auc                   0.494529 0.099452   0.325569   0.585154   0.504225\nprecision                0.475893 0.101162   0.320755   0.575758   0.437500\nr2                       0.208111 0.074940   0.094918   0.277467   0.182190\nrecall                   0.608449 0.040159   0.586207   0.558824   0.617647\nrmse                     0.313180 0.018242   0.326266   0.311326   0.331217\nspecificity              0.877964 0.050393   0.804348   0.921788   0.849162\n                        cv_4_valid cv_5_valid\naccuracy                  0.854460   0.886792\nauc                       0.774193   0.827427\nerr                       0.145540   0.113208\nerr_count                31.000000  24.000000\nf0point5                  0.519126   0.566038\nf1                        0.550725   0.600000\nf2                        0.586420   0.638298\nlift_top_group            6.870968   7.851852\nlogloss                   0.338992   0.281841\nmax_per_class_error       0.387097   0.333333\nmcc                       0.468385   0.538486\nmean_per_class_accuracy   0.754254   0.792793\nmean_per_class_error      0.245746   0.207207\nmse                       0.097805   0.080858\npr_auc                    0.515566   0.542129\nprecision                 0.500000   0.545455\nr2                        0.213525   0.272456\nrecall                    0.612903   0.666667\nrmse                      0.312737   0.284355\nspecificity               0.895604   0.918919\n```\n:::\n\n```{.r .cell-code}\n# Depending on the algorithm, the output will be different\nh2o.getModel(\"StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_4_AutoML_1_20230520_153140 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)             4/34\n3           # GBM base models (used / total)             1/20\n4           # GLM base models (used / total)              1/1\n5  # DeepLearning base models (used / total)             2/11\n6           # DRF base models (used / total)              0/2\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.05099553\nRMSE:  0.2258219\nLogLoss:  0.1968109\nMean Per-Class Error:  0.131307\nAUC:  0.9547642\nAUCPR:  0.8935755\nGini:  0.9095284\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error      Rate\nNo     899  10 0.011001   =10/909\nYes     39 116 0.251613   =39/155\nTotals 938 126 0.046053  =49/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.411252   0.825623 107\n2                       max f2  0.251631   0.832313 162\n3                 max f0point5  0.461778   0.895522  95\n4                 max accuracy  0.411252   0.953947 107\n5                max precision  0.959785   1.000000   0\n6                   max recall  0.023109   1.000000 365\n7              max specificity  0.959785   1.000000   0\n8             max absolute_mcc  0.411252   0.805111 107\n9   max min_per_class_accuracy  0.216889   0.896774 175\n10 max mean_per_class_accuracy  0.251631   0.905156 162\n11                     max tns  0.959785 909.000000   0\n12                     max fns  0.959785 154.000000   0\n13                     max fps  0.001195 909.000000 399\n14                     max tps  0.023109 155.000000 365\n15                     max tnr  0.959785   1.000000   0\n16                     max fnr  0.959785   0.993548   0\n17                     max fpr  0.001195   1.000000 399\n18                     max tpr  0.023109   1.000000 365\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.1062109\nRMSE:  0.3259001\nLogLoss:  0.3470929\nMean Per-Class Error:  0.2182241\nAUC:  0.8607232\nAUCPR:  0.6981044\nGini:  0.7214465\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error     Rate\nNo     137  10 0.068027  =10/147\nYes     14  24 0.368421   =14/38\nTotals 151  34 0.129730  =24/185\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.397164   0.666667  33\n2                       max f2  0.268551   0.703518  46\n3                 max f0point5  0.452942   0.724638  24\n4                 max accuracy  0.452942   0.875676  24\n5                max precision  0.918098   1.000000   0\n6                   max recall  0.029491   1.000000 146\n7              max specificity  0.918098   1.000000   0\n8             max absolute_mcc  0.403074   0.595848  30\n9   max min_per_class_accuracy  0.188694   0.761905  63\n10 max mean_per_class_accuracy  0.268551   0.803795  46\n11                     max tns  0.918098 147.000000   0\n12                     max fns  0.918098  37.000000   0\n13                     max fps  0.003240 147.000000 184\n14                     max tps  0.029491  38.000000 146\n15                     max tnr  0.918098   1.000000   0\n16                     max fnr  0.918098   0.973684   0\n17                     max fpr  0.003240   1.000000 184\n18                     max tpr  0.029491   1.000000 146\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.08464407\nRMSE:  0.2909365\nLogLoss:  0.2976949\nMean Per-Class Error:  0.2320522\nAUC:  0.8377693\nAUCPR:  0.6080058\nGini:  0.6755385\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error       Rate\nNo     839  70 0.077008    =70/909\nYes     60  95 0.387097    =60/155\nTotals 899 165 0.122180  =130/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.291059   0.593750 139\n2                       max f2  0.187189   0.641618 190\n3                 max f0point5  0.508023   0.647182  70\n4                 max accuracy  0.508023   0.894737  70\n5                max precision  0.965321   1.000000   0\n6                   max recall  0.002125   1.000000 398\n7              max specificity  0.965321   1.000000   0\n8             max absolute_mcc  0.291059   0.522283 139\n9   max min_per_class_accuracy  0.131740   0.761290 232\n10 max mean_per_class_accuracy  0.187189   0.784357 190\n11                     max tns  0.965321 909.000000   0\n12                     max fns  0.965321 154.000000   0\n13                     max fps  0.001109 909.000000 399\n14                     max tps  0.002125 155.000000 398\n15                     max tnr  0.965321   1.000000   0\n16                     max fnr  0.965321   0.993548   0\n17                     max fpr  0.001109   1.000000 399\n18                     max tpr  0.002125   1.000000 398\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n               mean       sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy   0.893982 0.029899   0.913706   0.880342   0.865217   0.874372\nauc        0.845190 0.030919   0.833987   0.820809   0.833419   0.838501\nerr        0.106018 0.029899   0.086294   0.119658   0.134783   0.125628\nerr_count 22.800000 7.563068  17.000000  28.000000  31.000000  25.000000\nf0point5   0.648896 0.131543   0.691057   0.670103   0.491329   0.558659\n          cv_5_valid\naccuracy    0.936275\nauc         0.899234\nerr         0.063725\nerr_count  13.000000\nf0point5    0.833333\n\n---\n                        mean        sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.659169  0.170264   0.708333   0.684211   0.472222\nr2                  0.317817  0.058259   0.333599   0.310833   0.244631\nrecall              0.641792  0.058347   0.629630   0.619048   0.586207\nresidual_deviance 125.817780 23.411427 112.322960 164.100600 130.606870\nrmse                0.289714  0.017228   0.280742   0.318582   0.288502\nspecificity         0.937130  0.038269   0.958824   0.937500   0.905473\n                  cv_4_valid cv_5_valid\nprecision           0.526316   0.904762\nr2                  0.295929   0.404091\nrecall              0.740741   0.633333\nresidual_deviance 117.523740 104.534730\nrmse                0.287343   0.273398\nspecificity         0.895349   0.988506\n```\n:::\n\n```{.r .cell-code}\n# Extracts and H2O model name by a position so can more easily use h2o.getModel()\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n    \n    model_name <- h2o_leaderboard %>%\n        as.tibble() %>%\n        slice(n) %>%\n        pull(model_id)\n    \n    if (verbose) message(model_name)\n    \n    return(model_name)\n    \n}\n\nautoml_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(6) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\ni Please use `as_tibble()` instead.\ni The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nStackedEnsemble_BestOfFamily_3_AutoML_12_20230520_160639\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_BestOfFamily_3_AutoML_12_20230520_160639 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)              3/5\n3           # GBM base models (used / total)              1/1\n4           # GLM base models (used / total)              1/1\n5           # DRF base models (used / total)              0/2\n6  # DeepLearning base models (used / total)              1/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.05747188\nRMSE:  0.2397329\nLogLoss:  0.213189\nMean Per-Class Error:  0.1454594\nAUC:  0.9299585\nAUCPR:  0.8356742\nGini:  0.859917\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error      Rate\nNo     885  24 0.026403   =24/909\nYes     41 114 0.264516   =41/155\nTotals 926 138 0.061090  =65/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.382037   0.778157 112\n2                       max f2  0.225267   0.787260 164\n3                 max f0point5  0.519569   0.828729  79\n4                 max accuracy  0.386540   0.939850 109\n5                max precision  0.974068   1.000000   0\n6                   max recall  0.003414   1.000000 394\n7              max specificity  0.974068   1.000000   0\n8             max absolute_mcc  0.386540   0.746142 109\n9   max min_per_class_accuracy  0.188749   0.872387 184\n10 max mean_per_class_accuracy  0.225267   0.878026 164\n11                     max tns  0.974068 909.000000   0\n12                     max fns  0.974068 154.000000   0\n13                     max fps  0.000527 909.000000 399\n14                     max tps  0.003414 155.000000 394\n15                     max tnr  0.974068   1.000000   0\n16                     max fnr  0.974068   0.993548   0\n17                     max fpr  0.000527   1.000000 399\n18                     max tpr  0.003414   1.000000 394\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.1015138\nRMSE:  0.3186123\nLogLoss:  0.3360956\nMean Per-Class Error:  0.1923559\nAUC:  0.8687791\nAUCPR:  0.7202894\nGini:  0.7375582\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error     Rate\nNo     133  14 0.095238  =14/147\nYes     11  27 0.289474   =11/38\nTotals 144  41 0.135135  =25/185\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.302958   0.683544  40\n2                       max f2  0.094104   0.723140  89\n3                 max f0point5  0.511139   0.714286  21\n4                 max accuracy  0.387801   0.875676  30\n5                max precision  0.932765   1.000000   0\n6                   max recall  0.015081   1.000000 146\n7              max specificity  0.932765   1.000000   0\n8             max absolute_mcc  0.302958   0.598489  40\n9   max min_per_class_accuracy  0.178994   0.789116  60\n10 max mean_per_class_accuracy  0.302958   0.807644  40\n11                     max tns  0.932765 147.000000   0\n12                     max fns  0.932765  37.000000   0\n13                     max fps  0.001134 147.000000 184\n14                     max tps  0.015081  38.000000 146\n15                     max tnr  0.932765   1.000000   0\n16                     max fnr  0.932765   0.973684   0\n17                     max fpr  0.001134   1.000000 184\n18                     max tpr  0.015081   1.000000 146\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.08458036\nRMSE:  0.290827\nLogLoss:  0.3011047\nMean Per-Class Error:  0.2101707\nAUC:  0.8404982\nAUCPR:  0.6127209\nGini:  0.6809965\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error       Rate\nNo     826  83 0.091309    =83/909\nYes     51 104 0.329032    =51/155\nTotals 877 187 0.125940  =134/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.264435   0.608187 144\n2                       max f2  0.243052   0.649272 154\n3                 max f0point5  0.409125   0.647359  92\n4                 max accuracy  0.409125   0.895677  92\n5                max precision  0.975409   1.000000   0\n6                   max recall  0.000526   1.000000 399\n7              max specificity  0.975409   1.000000   0\n8             max absolute_mcc  0.348124   0.539616 110\n9   max min_per_class_accuracy  0.149090   0.774194 217\n10 max mean_per_class_accuracy  0.243052   0.791806 154\n11                     max tns  0.975409 909.000000   0\n12                     max fns  0.975409 154.000000   0\n13                     max fps  0.000526 909.000000 399\n14                     max tps  0.000526 155.000000 399\n15                     max tnr  0.975409   1.000000   0\n16                     max fnr  0.975409   0.993548   0\n17                     max fpr  0.000526   1.000000 399\n18                     max tpr  0.000526   1.000000 399\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n               mean       sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy   0.890698 0.016969   0.897321   0.864078   0.903509   0.884058\nauc        0.838486 0.034757   0.868189   0.837681   0.864158   0.841210\nerr        0.109302 0.016969   0.102679   0.135922   0.096491   0.115942\nerr_count 23.200000 3.271085  23.000000  28.000000  22.000000  24.000000\nf0point5   0.623043 0.067312   0.696970   0.518293   0.652174   0.644330\n          cv_5_valid\naccuracy    0.904523\nauc         0.781190\nerr         0.095477\nerr_count  19.000000\nf0point5    0.603448\n\n---\n                        mean       sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.616805 0.078082   0.718750   0.500000   0.631579\nr2                  0.311282 0.075556   0.373039   0.237377   0.372755\nrecall              0.659478 0.077318   0.621622   0.607143   0.750000\nresidual_deviance 127.246840 6.482403 131.733630 123.568474 130.466490\nrmse                0.290809 0.009947   0.294032   0.299279   0.275098\nspecificity         0.929361 0.020934   0.951872   0.904494   0.928571\n                  cv_4_valid cv_5_valid\nprecision           0.625000   0.608696\nr2                  0.352056   0.221183\nrecall              0.735294   0.583333\nresidual_deviance 132.846790 117.618810\nrmse                0.298237   0.287402\nspecificity         0.913295   0.948571\n```\n:::\n\n```{.r .cell-code}\n#h2o.getModel(\"StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\") %>% \n#  h2o.saveModel(path = \"04_Modeling/h20_models/\")\n\nh2o.loadModel(\"04_Modeling/h20_models/StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_4_AutoML_1_20230520_153140 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)             4/34\n3           # GBM base models (used / total)             1/20\n4           # GLM base models (used / total)              1/1\n5  # DeepLearning base models (used / total)             2/11\n6           # DRF base models (used / total)              0/2\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.05099553\nRMSE:  0.2258219\nLogLoss:  0.1968109\nMean Per-Class Error:  0.131307\nAUC:  0.9547642\nAUCPR:  0.8935755\nGini:  0.9095284\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error      Rate\nNo     899  10 0.011001   =10/909\nYes     39 116 0.251613   =39/155\nTotals 938 126 0.046053  =49/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.411252   0.825623 107\n2                       max f2  0.251631   0.832313 162\n3                 max f0point5  0.461778   0.895522  95\n4                 max accuracy  0.411252   0.953947 107\n5                max precision  0.959785   1.000000   0\n6                   max recall  0.023109   1.000000 365\n7              max specificity  0.959785   1.000000   0\n8             max absolute_mcc  0.411252   0.805111 107\n9   max min_per_class_accuracy  0.216889   0.896774 175\n10 max mean_per_class_accuracy  0.251631   0.905156 162\n11                     max tns  0.959785 909.000000   0\n12                     max fns  0.959785 154.000000   0\n13                     max fps  0.001195 909.000000 399\n14                     max tps  0.023109 155.000000 365\n15                     max tnr  0.959785   1.000000   0\n16                     max fnr  0.959785   0.993548   0\n17                     max fpr  0.001195   1.000000 399\n18                     max tpr  0.023109   1.000000 365\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.1062109\nRMSE:  0.3259001\nLogLoss:  0.3470929\nMean Per-Class Error:  0.2182241\nAUC:  0.8607232\nAUCPR:  0.6981044\nGini:  0.7214465\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error     Rate\nNo     137  10 0.068027  =10/147\nYes     14  24 0.368421   =14/38\nTotals 151  34 0.129730  =24/185\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.397164   0.666667  33\n2                       max f2  0.268551   0.703518  46\n3                 max f0point5  0.452942   0.724638  24\n4                 max accuracy  0.452942   0.875676  24\n5                max precision  0.918098   1.000000   0\n6                   max recall  0.029491   1.000000 146\n7              max specificity  0.918098   1.000000   0\n8             max absolute_mcc  0.403074   0.595848  30\n9   max min_per_class_accuracy  0.188694   0.761905  63\n10 max mean_per_class_accuracy  0.268551   0.803795  46\n11                     max tns  0.918098 147.000000   0\n12                     max fns  0.918098  37.000000   0\n13                     max fps  0.003240 147.000000 184\n14                     max tps  0.029491  38.000000 146\n15                     max tnr  0.918098   1.000000   0\n16                     max fnr  0.918098   0.973684   0\n17                     max fpr  0.003240   1.000000 184\n18                     max tpr  0.029491   1.000000 146\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.08464407\nRMSE:  0.2909365\nLogLoss:  0.2976949\nMean Per-Class Error:  0.2320522\nAUC:  0.8377693\nAUCPR:  0.6080058\nGini:  0.6755385\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error       Rate\nNo     839  70 0.077008    =70/909\nYes     60  95 0.387097    =60/155\nTotals 899 165 0.122180  =130/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.291059   0.593750 139\n2                       max f2  0.187189   0.641618 190\n3                 max f0point5  0.508023   0.647182  70\n4                 max accuracy  0.508023   0.894737  70\n5                max precision  0.965321   1.000000   0\n6                   max recall  0.002125   1.000000 398\n7              max specificity  0.965321   1.000000   0\n8             max absolute_mcc  0.291059   0.522283 139\n9   max min_per_class_accuracy  0.131740   0.761290 232\n10 max mean_per_class_accuracy  0.187189   0.784357 190\n11                     max tns  0.965321 909.000000   0\n12                     max fns  0.965321 154.000000   0\n13                     max fps  0.001109 909.000000 399\n14                     max tps  0.002125 155.000000 398\n15                     max tnr  0.965321   1.000000   0\n16                     max fnr  0.965321   0.993548   0\n17                     max fpr  0.001109   1.000000 399\n18                     max tpr  0.002125   1.000000 398\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n               mean       sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy   0.893982 0.029899   0.913706   0.880342   0.865217   0.874372\nauc        0.845190 0.030919   0.833987   0.820809   0.833419   0.838501\nerr        0.106018 0.029899   0.086294   0.119658   0.134783   0.125628\nerr_count 22.800000 7.563068  17.000000  28.000000  31.000000  25.000000\nf0point5   0.648896 0.131543   0.691057   0.670103   0.491329   0.558659\n          cv_5_valid\naccuracy    0.936275\nauc         0.899234\nerr         0.063725\nerr_count  13.000000\nf0point5    0.833333\n\n---\n                        mean        sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.659169  0.170264   0.708333   0.684211   0.472222\nr2                  0.317817  0.058259   0.333599   0.310833   0.244631\nrecall              0.641792  0.058347   0.629630   0.619048   0.586207\nresidual_deviance 125.817780 23.411427 112.322960 164.100600 130.606870\nrmse                0.289714  0.017228   0.280742   0.318582   0.288502\nspecificity         0.937130  0.038269   0.958824   0.937500   0.905473\n                  cv_4_valid cv_5_valid\nprecision           0.526316   0.904762\nr2                  0.295929   0.404091\nrecall              0.740741   0.633333\nresidual_deviance 117.523740 104.534730\nrmse                0.287343   0.273398\nspecificity         0.895349   0.988506\n```\n:::\n\n```{.r .cell-code}\n# Choose whatever model you want\nstacked_ensemble_h2o <- h2o.loadModel(\"04_Modeling/h20_models/StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\")\nstacked_ensemble_h2o\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_4_AutoML_1_20230520_153140 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)             4/34\n3           # GBM base models (used / total)             1/20\n4           # GLM base models (used / total)              1/1\n5  # DeepLearning base models (used / total)             2/11\n6           # DRF base models (used / total)              0/2\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.05099553\nRMSE:  0.2258219\nLogLoss:  0.1968109\nMean Per-Class Error:  0.131307\nAUC:  0.9547642\nAUCPR:  0.8935755\nGini:  0.9095284\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error      Rate\nNo     899  10 0.011001   =10/909\nYes     39 116 0.251613   =39/155\nTotals 938 126 0.046053  =49/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.411252   0.825623 107\n2                       max f2  0.251631   0.832313 162\n3                 max f0point5  0.461778   0.895522  95\n4                 max accuracy  0.411252   0.953947 107\n5                max precision  0.959785   1.000000   0\n6                   max recall  0.023109   1.000000 365\n7              max specificity  0.959785   1.000000   0\n8             max absolute_mcc  0.411252   0.805111 107\n9   max min_per_class_accuracy  0.216889   0.896774 175\n10 max mean_per_class_accuracy  0.251631   0.905156 162\n11                     max tns  0.959785 909.000000   0\n12                     max fns  0.959785 154.000000   0\n13                     max fps  0.001195 909.000000 399\n14                     max tps  0.023109 155.000000 365\n15                     max tnr  0.959785   1.000000   0\n16                     max fnr  0.959785   0.993548   0\n17                     max fpr  0.001195   1.000000 399\n18                     max tpr  0.023109   1.000000 365\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.1062109\nRMSE:  0.3259001\nLogLoss:  0.3470929\nMean Per-Class Error:  0.2182241\nAUC:  0.8607232\nAUCPR:  0.6981044\nGini:  0.7214465\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error     Rate\nNo     137  10 0.068027  =10/147\nYes     14  24 0.368421   =14/38\nTotals 151  34 0.129730  =24/185\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.397164   0.666667  33\n2                       max f2  0.268551   0.703518  46\n3                 max f0point5  0.452942   0.724638  24\n4                 max accuracy  0.452942   0.875676  24\n5                max precision  0.918098   1.000000   0\n6                   max recall  0.029491   1.000000 146\n7              max specificity  0.918098   1.000000   0\n8             max absolute_mcc  0.403074   0.595848  30\n9   max min_per_class_accuracy  0.188694   0.761905  63\n10 max mean_per_class_accuracy  0.268551   0.803795  46\n11                     max tns  0.918098 147.000000   0\n12                     max fns  0.918098  37.000000   0\n13                     max fps  0.003240 147.000000 184\n14                     max tps  0.029491  38.000000 146\n15                     max tnr  0.918098   1.000000   0\n16                     max fnr  0.918098   0.973684   0\n17                     max fpr  0.003240   1.000000 184\n18                     max tpr  0.029491   1.000000 146\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.08464407\nRMSE:  0.2909365\nLogLoss:  0.2976949\nMean Per-Class Error:  0.2320522\nAUC:  0.8377693\nAUCPR:  0.6080058\nGini:  0.6755385\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n        No Yes    Error       Rate\nNo     839  70 0.077008    =70/909\nYes     60  95 0.387097    =60/155\nTotals 899 165 0.122180  =130/1064\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold      value idx\n1                       max f1  0.291059   0.593750 139\n2                       max f2  0.187189   0.641618 190\n3                 max f0point5  0.508023   0.647182  70\n4                 max accuracy  0.508023   0.894737  70\n5                max precision  0.965321   1.000000   0\n6                   max recall  0.002125   1.000000 398\n7              max specificity  0.965321   1.000000   0\n8             max absolute_mcc  0.291059   0.522283 139\n9   max min_per_class_accuracy  0.131740   0.761290 232\n10 max mean_per_class_accuracy  0.187189   0.784357 190\n11                     max tns  0.965321 909.000000   0\n12                     max fns  0.965321 154.000000   0\n13                     max fps  0.001109 909.000000 399\n14                     max tps  0.002125 155.000000 398\n15                     max tnr  0.965321   1.000000   0\n16                     max fnr  0.965321   0.993548   0\n17                     max fpr  0.001109   1.000000 399\n18                     max tpr  0.002125   1.000000 398\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n               mean       sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy   0.893982 0.029899   0.913706   0.880342   0.865217   0.874372\nauc        0.845190 0.030919   0.833987   0.820809   0.833419   0.838501\nerr        0.106018 0.029899   0.086294   0.119658   0.134783   0.125628\nerr_count 22.800000 7.563068  17.000000  28.000000  31.000000  25.000000\nf0point5   0.648896 0.131543   0.691057   0.670103   0.491329   0.558659\n          cv_5_valid\naccuracy    0.936275\nauc         0.899234\nerr         0.063725\nerr_count  13.000000\nf0point5    0.833333\n\n---\n                        mean        sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.659169  0.170264   0.708333   0.684211   0.472222\nr2                  0.317817  0.058259   0.333599   0.310833   0.244631\nrecall              0.641792  0.058347   0.629630   0.619048   0.586207\nresidual_deviance 125.817780 23.411427 112.322960 164.100600 130.606870\nrmse                0.289714  0.017228   0.280742   0.318582   0.288502\nspecificity         0.937130  0.038269   0.958824   0.937500   0.905473\n                  cv_4_valid cv_5_valid\nprecision           0.526316   0.904762\nr2                  0.295929   0.404091\nrecall              0.740741   0.633333\nresidual_deviance 117.523740 104.534730\nrmse                0.287343   0.273398\nspecificity         0.895349   0.988506\n```\n:::\n\n```{.r .cell-code}\npredictions <- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntypeof(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"environment\"\n```\n:::\n\n```{.r .cell-code}\n## [1] \"environment\"\n\npredictions_tbl <- predictions %>% as_tibble()\n\ndeep_learning_h2o <- h2o.loadModel(\"04_Modeling/h20_models/StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\")\n\n# To see all possible parameters\n#?h2o.deeplearning\n\n# to get all paramteres\ndeep_learning_h2o@allparameters\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$model_id\n[1] \"StackedEnsemble_AllModels_4_AutoML_1_20230520_153140\"\n\n$training_frame\n[1] \"AutoML_1_20230520_153140_training_RTMP_sid_a125_10\"\n\n$base_models\n$base_models[[1]]\n$base_models[[1]]$`__meta`\n$base_models[[1]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[1]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[1]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[1]]$name\n[1] \"GLM_1_AutoML_1_20230520_153140\"\n\n$base_models[[1]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[1]]$URL\nNULL\n\n\n$base_models[[2]]\n$base_models[[2]]$`__meta`\n$base_models[[2]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[2]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[2]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[2]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_3\"\n\n$base_models[[2]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[2]]$URL\nNULL\n\n\n$base_models[[3]]\n$base_models[[3]]$`__meta`\n$base_models[[3]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[3]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[3]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[3]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_2\"\n\n$base_models[[3]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[3]]$URL\nNULL\n\n\n$base_models[[4]]\n$base_models[[4]]$`__meta`\n$base_models[[4]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[4]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[4]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[4]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_4\"\n\n$base_models[[4]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[4]]$URL\nNULL\n\n\n$base_models[[5]]\n$base_models[[5]]$`__meta`\n$base_models[[5]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[5]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[5]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[5]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_11\"\n\n$base_models[[5]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[5]]$URL\nNULL\n\n\n$base_models[[6]]\n$base_models[[6]]$`__meta`\n$base_models[[6]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[6]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[6]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[6]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_7\"\n\n$base_models[[6]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[6]]$URL\nNULL\n\n\n$base_models[[7]]\n$base_models[[7]]$`__meta`\n$base_models[[7]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[7]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[7]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[7]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_3\"\n\n$base_models[[7]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[7]]$URL\nNULL\n\n\n$base_models[[8]]\n$base_models[[8]]$`__meta`\n$base_models[[8]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[8]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[8]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[8]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_6\"\n\n$base_models[[8]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[8]]$URL\nNULL\n\n\n$base_models[[9]]\n$base_models[[9]]$`__meta`\n$base_models[[9]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[9]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[9]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[9]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_8\"\n\n$base_models[[9]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[9]]$URL\nNULL\n\n\n$base_models[[10]]\n$base_models[[10]]$`__meta`\n$base_models[[10]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[10]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[10]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[10]]$name\n[1] \"DRF_1_AutoML_1_20230520_153140\"\n\n$base_models[[10]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[10]]$URL\nNULL\n\n\n$base_models[[11]]\n$base_models[[11]]$`__meta`\n$base_models[[11]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[11]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[11]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[11]]$name\n[1] \"GBM_2_AutoML_1_20230520_153140\"\n\n$base_models[[11]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[11]]$URL\nNULL\n\n\n$base_models[[12]]\n$base_models[[12]]$`__meta`\n$base_models[[12]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[12]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[12]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[12]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_1\"\n\n$base_models[[12]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[12]]$URL\nNULL\n\n\n$base_models[[13]]\n$base_models[[13]]$`__meta`\n$base_models[[13]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[13]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[13]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[13]]$name\n[1] \"GBM_5_AutoML_1_20230520_153140\"\n\n$base_models[[13]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[13]]$URL\nNULL\n\n\n$base_models[[14]]\n$base_models[[14]]$`__meta`\n$base_models[[14]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[14]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[14]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[14]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_2\"\n\n$base_models[[14]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[14]]$URL\nNULL\n\n\n$base_models[[15]]\n$base_models[[15]]$`__meta`\n$base_models[[15]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[15]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[15]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[15]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_9\"\n\n$base_models[[15]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[15]]$URL\nNULL\n\n\n$base_models[[16]]\n$base_models[[16]]$`__meta`\n$base_models[[16]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[16]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[16]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[16]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_5\"\n\n$base_models[[16]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[16]]$URL\nNULL\n\n\n$base_models[[17]]\n$base_models[[17]]$`__meta`\n$base_models[[17]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[17]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[17]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[17]]$name\n[1] \"GBM_1_AutoML_1_20230520_153140\"\n\n$base_models[[17]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[17]]$URL\nNULL\n\n\n$base_models[[18]]\n$base_models[[18]]$`__meta`\n$base_models[[18]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[18]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[18]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[18]]$name\n[1] \"DeepLearning_grid_2_AutoML_1_20230520_153140_model_1\"\n\n$base_models[[18]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[18]]$URL\nNULL\n\n\n$base_models[[19]]\n$base_models[[19]]$`__meta`\n$base_models[[19]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[19]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[19]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[19]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_5\"\n\n$base_models[[19]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[19]]$URL\nNULL\n\n\n$base_models[[20]]\n$base_models[[20]]$`__meta`\n$base_models[[20]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[20]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[20]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[20]]$name\n[1] \"GBM_3_AutoML_1_20230520_153140\"\n\n$base_models[[20]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[20]]$URL\nNULL\n\n\n$base_models[[21]]\n$base_models[[21]]$`__meta`\n$base_models[[21]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[21]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[21]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[21]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_14\"\n\n$base_models[[21]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[21]]$URL\nNULL\n\n\n$base_models[[22]]\n$base_models[[22]]$`__meta`\n$base_models[[22]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[22]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[22]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[22]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_10\"\n\n$base_models[[22]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[22]]$URL\nNULL\n\n\n$base_models[[23]]\n$base_models[[23]]$`__meta`\n$base_models[[23]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[23]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[23]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[23]]$name\n[1] \"DeepLearning_1_AutoML_1_20230520_153140\"\n\n$base_models[[23]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[23]]$URL\nNULL\n\n\n$base_models[[24]]\n$base_models[[24]]$`__meta`\n$base_models[[24]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[24]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[24]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[24]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_13\"\n\n$base_models[[24]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[24]]$URL\nNULL\n\n\n$base_models[[25]]\n$base_models[[25]]$`__meta`\n$base_models[[25]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[25]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[25]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[25]]$name\n[1] \"XRT_1_AutoML_1_20230520_153140\"\n\n$base_models[[25]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[25]]$URL\nNULL\n\n\n$base_models[[26]]\n$base_models[[26]]$`__meta`\n$base_models[[26]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[26]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[26]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[26]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_12\"\n\n$base_models[[26]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[26]]$URL\nNULL\n\n\n$base_models[[27]]\n$base_models[[27]]$`__meta`\n$base_models[[27]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[27]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[27]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[27]]$name\n[1] \"GBM_grid_1_AutoML_1_20230520_153140_model_15\"\n\n$base_models[[27]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[27]]$URL\nNULL\n\n\n$base_models[[28]]\n$base_models[[28]]$`__meta`\n$base_models[[28]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[28]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[28]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[28]]$name\n[1] \"GBM_4_AutoML_1_20230520_153140\"\n\n$base_models[[28]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[28]]$URL\nNULL\n\n\n$base_models[[29]]\n$base_models[[29]]$`__meta`\n$base_models[[29]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[29]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[29]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[29]]$name\n[1] \"DeepLearning_grid_2_AutoML_1_20230520_153140_model_2\"\n\n$base_models[[29]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[29]]$URL\nNULL\n\n\n$base_models[[30]]\n$base_models[[30]]$`__meta`\n$base_models[[30]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[30]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[30]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[30]]$name\n[1] \"DeepLearning_grid_3_AutoML_1_20230520_153140_model_2\"\n\n$base_models[[30]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[30]]$URL\nNULL\n\n\n$base_models[[31]]\n$base_models[[31]]$`__meta`\n$base_models[[31]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[31]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[31]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[31]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_6\"\n\n$base_models[[31]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[31]]$URL\nNULL\n\n\n$base_models[[32]]\n$base_models[[32]]$`__meta`\n$base_models[[32]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[32]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[32]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[32]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_4\"\n\n$base_models[[32]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[32]]$URL\nNULL\n\n\n$base_models[[33]]\n$base_models[[33]]$`__meta`\n$base_models[[33]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[33]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[33]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[33]]$name\n[1] \"DeepLearning_grid_1_AutoML_1_20230520_153140_model_1\"\n\n$base_models[[33]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[33]]$URL\nNULL\n\n\n$base_models[[34]]\n$base_models[[34]]$`__meta`\n$base_models[[34]]$`__meta`$schema_version\n[1] 3\n\n$base_models[[34]]$`__meta`$schema_name\n[1] \"KeyV3\"\n\n$base_models[[34]]$`__meta`$schema_type\n[1] \"Key<Keyed>\"\n\n\n$base_models[[34]]$name\n[1] \"DeepLearning_grid_3_AutoML_1_20230520_153140_model_1\"\n\n$base_models[[34]]$type\n[1] \"Key<Keyed>\"\n\n$base_models[[34]]$URL\nNULL\n\n\n\n$metalearner_algorithm\n[1] \"glm\"\n\n$metalearner_nfolds\n[1] 5\n\n$metalearner_params\n[1] \"\"\n\n$metalearner_transform\n[1] \"Logit\"\n\n$max_runtime_secs\n[1] 0.582\n\n$seed\n[1] \"5790433738836513710\"\n\n$score_training_samples\n[1] 10000\n\n$keep_levelone_frame\n[1] TRUE\n\n$auc_type\n[1] \"AUTO\"\n\n$x\n [1] \"Age\"                      \"BusinessTravel\"          \n [3] \"DailyRate\"                \"Department\"              \n [5] \"DistanceFromHome\"         \"Education\"               \n [7] \"EducationField\"           \"EmployeeNumber\"          \n [9] \"EnvironmentSatisfaction\"  \"Gender\"                  \n[11] \"HourlyRate\"               \"JobInvolvement\"          \n[13] \"JobLevel\"                 \"JobRole\"                 \n[15] \"JobSatisfaction\"          \"MaritalStatus\"           \n[17] \"MonthlyIncome\"            \"MonthlyRate\"             \n[19] \"NumCompaniesWorked\"       \"OverTime\"                \n[21] \"PercentSalaryHike\"        \"PerformanceRating\"       \n[23] \"RelationshipSatisfaction\" \"StockOptionLevel\"        \n[25] \"TotalWorkingYears\"        \"TrainingTimesLastYear\"   \n[27] \"WorkLifeBalance\"          \"YearsAtCompany\"          \n[29] \"YearsInCurrentRole\"       \"YearsSinceLastPromotion\" \n[31] \"YearsWithCurrManager\"    \n\n$y\n[1] \"Attrition\"\n```\n:::\n:::\n\n\n\n# Challenge (Part II)\n\n::: {.cell hash='03_automated_maschine_learning_with_H2O_cache/html/unnamed-chunk-13_7b9894556cb3e8c74c21fb858195e3a4'}\n\n```{.r .cell-code}\n#1. Load the training & test dataset\nemployee_attrition_tbl          <- read_csv(\"product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 19053 Columns: 23\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\ndbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nset.seed(seed = 1113)\nsplit_obj                       <- rsample::initial_split(employee_attrition_tbl, prop = 0.85)\ntrain_readable_tbl              <- training(split_obj)\ntest_readable_tbl               <- testing(split_obj)\n\n#2. Specifiy the response and predictor variables\nrecipe_obj <- recipe(went_on_backorder ~., data = train_readable_tbl) %>% \n    step_zv(all_predictors()) %>% \n    #step_mutate_at(JobLevel, StockOptionLevel, fn = as.factor) %>% \n    prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# Modeling\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 hours 42 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.40.0.1 \n    H2O cluster version age:    3 months and 11 days \n    H2O cluster name:           H2O_started_from_R_Chris_yuh446 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.41 GB \n    H2O cluster total cores:    12 \n    H2O cluster allowed cores:  12 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.0.5 (2021-03-31) \n```\n:::\n\n```{.r .cell-code}\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\n\n#3. Run AutoML specifying the stopping criterion\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   4%\n16:07:24.670: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n16:07:24.671: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n#4. View the leaderboard\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                  model_id       auc   logloss\n1                          GBM_3_AutoML_13_20230520_160724 0.9499044 0.1770730\n2    StackedEnsemble_AllModels_2_AutoML_13_20230520_160724 0.9486058 0.1769352\n3                          GBM_4_AutoML_13_20230520_160724 0.9485561 0.1802068\n4    StackedEnsemble_AllModels_1_AutoML_13_20230520_160724 0.9482098 0.1773253\n5 StackedEnsemble_BestOfFamily_3_AutoML_13_20230520_160724 0.9478242 0.1760591\n6                          GBM_2_AutoML_13_20230520_160724 0.9476206 0.1807871\n      aucpr mean_per_class_error      rmse        mse\n1 0.7437243            0.1476268 0.2297593 0.05278934\n2 0.7395176            0.1321888 0.2308383 0.05328632\n3 0.7319715            0.1370083 0.2329250 0.05425408\n4 0.7414366            0.1305364 0.2310062 0.05336387\n5 0.7443698            0.1443220 0.2287742 0.05233762\n6 0.7316043            0.1394563 0.2331993 0.05438189\n\n[16 rows x 7 columns] \n```\n:::\n\n```{.r .cell-code}\n# Extracts and H2O model name by a position so can more easily use h2o.getModel()\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n    \n    model_name <- h2o_leaderboard %>%\n        as.tibble() %>%\n        slice(n) %>%\n        pull(model_id)\n    \n    if (verbose) message(model_name)\n    \n    return(model_name)\n    \n}\n\n#Retrieve leader model\nleader_model <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position() %>%\n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nGBM_3_AutoML_13_20230520_160724\n```\n:::\n\n```{.r .cell-code}\n#5. Predicting using Leader Model\npredictions <- h2o.predict(leader_model, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n#6. Save the leader model\nleader_model %>% h2o.saveModel(path = \"04_Modeling/h20_models/\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"D:\\\\Dokumente\\\\8gb stick\\\\OneDrive - tuhh.de\\\\Semester_VIII\\\\BundM\\\\MaschineLearning\\\\ss23-bdml-ginger4711\\\\src\\\\Data\\\\04_Modeling\\\\h20_models\\\\GBM_3_AutoML_13_20230520_160724\"\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}